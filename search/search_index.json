{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> Explore the docs \u00bb Quickstart     \u00b7     Feature Request     \u00b7     Report Bug     \u00b7     Discussions     \u00b7     About </p> <p>The goal of this project is to create a framework for the active learning loop for computer vision. The diagram below shows a general workflow of how the active learning loop works.</p> <p> </p>"},{"location":"#supported-tasks","title":"Supported tasks:","text":"<ul> <li>[X] Image classification</li> <li>[ ] Object detection</li> <li>[ ] Segmentation</li> </ul>"},{"location":"#supported-models","title":"Supported models:","text":"<ul> <li>[X] Fastai models</li> <li>[X] Torchvision models</li> <li>[X] Timm models</li> <li>[ ] Hugging Face models</li> </ul>"},{"location":"#supported-active-learning-strategies","title":"Supported Active Learning Strategies:","text":"<p>Uncertainty Sampling: - [X] Least confidence - [X] Margin of confidence - [X] Ratio of confidence - [X] Entropy</p> <p>Diverse Sampling: - [X] Random sampling - [X] Model-based outlier - [ ] Embeddings-based outlier - [ ] Cluster-based - [ ] Representative</p>"},{"location":"#installation","title":"\ud83d\udce6 Installation","text":"<p>Get a release from PyPI <pre><code>pip install active-vision\n</code></pre></p> <p>Install from source <pre><code>git clone https://github.com/dnth/active-vision.git\ncd active-vision\npip install -e .\n</code></pre></p> <p>[!TIP] I recommend using uv to set up a virtual environment and install the package. You can also use other virtual env of your choice.</p> <p>If you're using uv:</p> <p><pre><code>uv venv\nuv sync\n</code></pre> Once the virtual environment is created, you can install the package using pip.</p> <p>If you're using uv add a <code>uv</code> before the pip install command to install into your virtual environment. Eg: <pre><code>uv pip install active-vision\n</code></pre></p>"},{"location":"#quickstart","title":"\ud83d\ude80 Quickstart","text":"<pre><code>from active_vision import ActiveLearner\n\n# Create an active learner instance\nal = ActiveLearner(name=\"cycle-1\")\n\n# Load model\nal.load_model(model=\"resnet18\", pretrained=True)\n\n# Load dataset \ntrain_df = pd.read_parquet(\"training_samples.parquet\")\nal.load_dataset(train_df, filepath_col=\"filepath\", label_col=\"label\", batch_size=8)\n\n# Train model\nal.train(epochs=10, lr=5e-3, head_tuning_epochs=3)\n\n# Evaluate the model on a *labeled* evaluation set\naccuracy = al.evaluate(eval_df, filepath_col=\"filepath\", label_col=\"label\")\n\n# Get summary of the active learning cycle\nal.summary()\n\n# Get predictions from an *unlabeled* set\npred_df = al.predict(filepaths)\n\n# Sample images using a combination of active learning strategies\nsamples = al.sample_combination(\n    pred_df,\n    num_samples=50,\n    combination={\n        \"least-confidence\": 0.4,\n        \"ratio-of-confidence\": 0.2,\n        \"entropy\": 0.2,\n        \"model-based-outlier\": 0.1,\n        \"random\": 0.1,\n    },\n)\n\n# Launch a Gradio UI to label the low confidence samples, save the labeled samples to a file\nal.label(samples, output_filename=\"combination.parquet\")\n</code></pre> <p>In the UI, you can optionally run zero-shot inference on the image. This will use a VLM to predict the label of the image. There are a dozen VLM models as supported in the x.infer project.</p> <p></p> <p>Once complete, the labeled samples will be save into a new df. We can now add the newly labeled data to the training set.</p> <pre><code># Add newly labeled data to the dataset\nal.add_to_dataset(labeled_df, output_filename=\"active_labeled.parquet\")\n</code></pre> <p>Repeat the process until the model is good enough. Use the dataset to train a larger model and deploy.</p> <p>[!TIP] For the toy dataset, I got to about 93% accuracy on the evaluation set with 200+ labeled images. The best performing model on the leaderboard got 95.11% accuracy training on all 9469 labeled images.</p> <p>This took me about 6 iterations of relabeling. Each iteration took about 5 minutes to complete including labeling and model training (resnet18). See the notebook for more details.</p> <p>But using the dataset of 200+ images, I trained a more capable model (convnext_small_in22k) and got 99.3% accuracy on the evaluation set. See the notebook for more details.</p>"},{"location":"#benchmarks","title":"\ud83d\udcca Benchmarks","text":"<p>This section contains the benchmarks I ran using the active learning loop on various datasets.</p> <p>Column description: - <code>#Labeled Images</code>: The number of labeled images used to train the model. - <code>Evaluation Accuracy</code>: The accuracy of the model on the evaluation set. - <code>Train Epochs</code>: The number of epochs used to train the model. - <code>Model</code>: The model used to train. - <code>Active Learning</code>: Whether active learning was used to train the model. - <code>Source</code>: The source of the results.</p>"},{"location":"#imagenette","title":"Imagenette","text":"<ul> <li>num classes: 10</li> <li>num images: 9469</li> </ul> <p>To start the active learning loop, I labeled 100 images (10 images from each class) and iteratively relabeled the most informative images until I hit 275 labeled images. </p> <p>The active learning loop is a iterative process and can keep going until you hit a stopping point. You can decide your own stopping point based on your use case. It could be: - You ran out of data to label. - You hit a performance goal. - You hit a budget. - Other criteria.</p> <p>For this dataset, I decided to stop the active learning loop at 275 labeled images because the performance on the evaluation set exceeds the top performing model on the leaderboard. </p> #Labeled Images Evaluation Accuracy Train Epochs Model Active Learning Source 9469 94.90% 80 xse_resnext50 \u274c Link 9469 95.11% 200 xse_resnext50 \u274c Link 275 99.33% 6 convnext_small_in22k \u2713 Link 275 93.40% 4 resnet18 \u2713 Link"},{"location":"#dog-food","title":"Dog Food","text":"<ul> <li>num classes: 2</li> <li>num images: 2100</li> </ul> <p>To start the active learning loop, I labeled 20 images (10 images from each class) and iteratively relabeled the most informative images until I hit 160 labeled images. </p> <p>I decided to stop the active learning loop at 160 labeled images because the performance on the evaluation set is close to the top performing model on the leaderboard. You can decide your own stopping point based on your use case.</p> #Labeled Images Evaluation Accuracy Train Epochs Model Active Learning Source 2100 99.70% ? vit-base-patch16-224 \u274c Link 160 100.00% 6 convnext_small_in22k \u2713 Link 160 97.60% 4 resnet18 \u2713 Link"},{"location":"#oxford-iiit-pet","title":"Oxford-IIIT Pet","text":"<ul> <li>num classes: 37</li> <li>num images: 3680</li> </ul> <p>To start the active learning loop, I labeled 370 images (10 images from each class) and iteratively relabeled the most informative images until I hit 612 labeled images. </p> <p>I decided to stop the active learning loop at 612 labeled images because the performance on the evaluation set is close to the top performing model on the leaderboard. You can decide your own stopping point based on your use case.</p> #Labeled Images Evaluation Accuracy Train Epochs Model Active Learning Source 3680 95.40% 5 vit-base-patch16-224 \u274c Link 612 90.26% 11 convnext_small_in22k \u2713 Link 612 91.38% 11 vit-base-patch16-224 \u2713 Link"},{"location":"#eurosat-rgb","title":"Eurosat RGB","text":"<ul> <li>num classes: 10</li> <li>num images: 16100</li> </ul> <p>To start the active learning loop, I labeled 100 images (10 images from each class) and iteratively labeled the most informative images until I hit 1188 labeled images. </p> <p>I decided to stop the active learning loop at 1188 labeled images because the performance on the evaluation set is close to the top performing model on the leaderboard. You can decide your own stopping point based on your use case.</p> #Labeled Images Evaluation Accuracy Train Epochs Model Active Learning Source 16100 98.55% 6 vit-base-patch16-224 \u274c Link 1188 94.59% 6 vit-base-patch16-224 \u2713 Link 1188 96.57% 13 vit-base-patch16-224 \u2713 Link"},{"location":"#workflow","title":"\u27bf Workflow","text":"<p>This section describes a more detailed workflow for active learning. There are two workflows for active learning that we can use depending on the availability of labeled data.</p>"},{"location":"#with-unlabeled-data","title":"With unlabeled data","text":"<p>If we have no labeled data, the goal of the active learning loop is to build a resonably good labeled dataset to train a larger model.</p> <p>Steps:</p> <ol> <li>Load a small proxy model.</li> <li>Label an initial dataset. If there is none, you'll have to label some images.</li> <li>Train the proxy model on the labeled dataset.</li> <li>Run inference on the unlabeled dataset.</li> <li>Evaluate the performance of the proxy model.</li> <li>Is model good enough?    <ul> <li>Yes: Save the proxy model and the dataset.</li> <li>No: Select the most informative images to label using active learning.</li> </ul> </li> <li>Label the most informative images and add them to the dataset.</li> <li>Repeat steps 3-6.</li> <li>Save the proxy model and the dataset.</li> <li>Train a larger model on the saved dataset.</li> </ol> <pre><code>graph TD\n    A[Load a small proxy model] --&gt; B[Label an initial dataset]\n    B --&gt; C[Train proxy model on labeled dataset]\n    C --&gt; D[Run inference on unlabeled dataset]\n    D --&gt; E[Evaluate proxy model performance]\n    E --&gt; F{Model good enough?}\n    F --&gt;|Yes| G[Save proxy model and dataset]\n    G --&gt; H[Train and deploy a larger model]\n    F --&gt;|No| I[Select informative images using active learning]\n    I --&gt; J[Label selected images]\n    J --&gt; C\n</code></pre>"},{"location":"#with-labeled-data","title":"With labeled data","text":"<p>If we already have a labeled dataset, the goal of the active learning loop is to iteratively improve the dataset and the model by fixing the most important label errors.</p> <p>Steps:</p> <ol> <li>Load a small proxy model.</li> <li>Train the proxy model on the labeled dataset.</li> <li>Run inference on the entire labeled dataset.</li> <li>Get the most impactful label errors with active learning.</li> <li>Fix the label errors.</li> <li>Repeat steps 2-5 until the dataset is good enough.</li> <li>Save the labeled dataset.</li> <li>Train a larger model on the saved labeled dataset.</li> </ol> <pre><code>graph TD\n    A[Load a small proxy model] --&gt; B[Train proxy model on labeled dataset]\n    B --&gt; C[Run inference on labeled dataset]\n    C --&gt; D[Get label errors using active learning]\n    D --&gt; E[Fix label errors]\n    E --&gt; F{Dataset good enough?}\n    F --&gt;|No| B\n    F --&gt;|Yes| G[Save cleaned dataset]\n    G --&gt; H[Train and deploy larger model]\n</code></pre>"},{"location":"#sampling-approaches","title":"\ud83e\uddf1 Sampling Approaches","text":"<p>Recommendation 1: - 10% randomly selected from unlabeled items. - 80% selected from the lowest confidence items. - 10% selected as outliers.</p> <p>Recommendation 2:</p> <ul> <li>Sample 100 predicted images at 10\u201320% confidence.</li> <li>Sample 100 predicted images at 20\u201330% confidence.</li> <li>Sample 100 predicted images at 30\u201340% confidence, and so on.</li> </ul> <p>Uncertainty and diversity sampling are most effective when combined. For instance, you could first sample the most uncertain items using an uncertainty sampling method, then apply a diversity sampling method such as clustering to select a diverse set from the uncertain items.</p> <p>Ultimately, the right ratios can depend on the specific task and dataset.</p>"},{"location":"active_learning/","title":"Active Learning Cycle","text":""},{"location":"active_learning/#introduction","title":"Introduction","text":"<p>This notebook will guide you through the basic steps to get started with Active Vision.</p> <p>By the end of this notebook, you will be able to:</p> <ul> <li>Understand the basic workflow of active learning</li> <li>Understand the basic components of Active Vision</li> <li>Understand how to use Active Vision to train a model</li> <li>Understand how to use Active Vision to iteratively improve your dataset</li> </ul>"},{"location":"active_learning/#create-an-activelearner","title":"Create an ActiveLearner","text":"<p>Now that we have an initial dataset, we can load it into an <code>ActiveLearner</code> object with a model.</p> <p>Any fastai and timm models are supported. For simplicity, we will use a <code>resnet18</code> model.</p> <pre><code>from active_vision import ActiveLearner\n\nal = ActiveLearner(name=\"cycle-1\")\nal.load_model(model=\"resnet18\", pretrained=True, device=\"mps\")\n</code></pre> <pre><code>2025-02-01 22:44:09.797 | INFO     | active_vision.core:load_model:70 - Loading a pretrained timm model `resnet18` on `mps`\n</code></pre> <p>We can load the initial samples into the <code>ActiveLearner</code> object.</p> <pre><code>initial_samples.head()\n</code></pre> filepath label 0 data/imagenette/train/n02102040/n02102040_2788... English springer 1 data/imagenette/train/n02102040/n02102040_3759... English springer 2 data/imagenette/train/n02102040/n02102040_1916... English springer 3 data/imagenette/train/n02102040/n02102040_6147... English springer 4 data/imagenette/train/n02102040/n02102040_403.... English springer <pre><code>al.load_dataset(\n    initial_samples, filepath_col=\"filepath\", label_col=\"label\", batch_size=8\n)\n</code></pre> <pre><code>2025-02-01 22:44:50.385 | INFO     | active_vision.core:load_dataset:119 - Loading dataset from `filepath` and `label` columns\n2025-02-01 22:44:50.407 | INFO     | active_vision.core:load_dataset:153 - Creating new learner\n2025-02-01 22:44:50.872 | INFO     | active_vision.core:_optimize_learner:97 - Enabled mixed precision training\n2025-02-01 22:44:50.873 | INFO     | active_vision.core:_finalize_setup:105 - Done. Ready to train.\n</code></pre> <p>Let's inspect one batch of the train set.</p> <pre><code>al.show_batch()\n</code></pre> <p></p> <p>You can inspect the train and validation sets too.</p> <pre><code>al.train_set\n</code></pre> filepath label 74 data/imagenette/train/n03445777/n03445777_1058... golf ball 36 data/imagenette/train/n03000684/n03000684_1404... chain saw 68 data/imagenette/train/n03425413/n03425413_2060... gas pump 54 data/imagenette/train/n03417042/n03417042_3669... garbage truck 24 data/imagenette/train/n02979186/n02979186_1658... cassette player ... ... ... 42 data/imagenette/train/n03028079/n03028079_1565... church 30 data/imagenette/train/n03000684/n03000684_9935... chain saw 13 data/imagenette/train/n03394916/n03394916_5292... French horn 59 data/imagenette/train/n03417042/n03417042_79.JPEG garbage truck 0 data/imagenette/train/n02102040/n02102040_2788... English springer <p>80 rows \u00d7 2 columns</p> <pre><code>al.valid_set\n</code></pre> filepath label 96 data/imagenette/train/n01440764/n01440764_3153... tench 73 data/imagenette/train/n03445777/n03445777_4615... golf ball 67 data/imagenette/train/n03425413/n03425413_2016... gas pump 14 data/imagenette/train/n03394916/n03394916_3273... French horn 63 data/imagenette/train/n03425413/n03425413_1357... gas pump 52 data/imagenette/train/n03417042/n03417042_2137... garbage truck 78 data/imagenette/train/n03445777/n03445777_1806... golf ball 10 data/imagenette/train/n03394916/n03394916_6099... French horn 16 data/imagenette/train/n03394916/n03394916_4308... French horn 93 data/imagenette/train/n01440764/n01440764_1383... tench 60 data/imagenette/train/n03425413/n03425413_4937... gas pump 17 data/imagenette/train/n03394916/n03394916_4065... French horn 33 data/imagenette/train/n03000684/n03000684_2624... chain saw 8 data/imagenette/train/n02102040/n02102040_1388... English springer 38 data/imagenette/train/n03000684/n03000684_1371... chain saw 61 data/imagenette/train/n03425413/n03425413_2658... gas pump 39 data/imagenette/train/n03000684/n03000684_2753... chain saw 5 data/imagenette/train/n02102040/n02102040_8296... English springer 62 data/imagenette/train/n03425413/n03425413_1759... gas pump 40 data/imagenette/train/n03028079/n03028079_3132... church"},{"location":"active_learning/#train","title":"Train","text":"<p>Now that we have the initial dataset, we can train the model.</p> <p>But first, let's check the optimal learning rate for the model.</p> <pre><code>al.lr_find()\n</code></pre> <pre><code>2025-02-01 22:45:36.137 | INFO     | active_vision.core:lr_find:194 - Finding optimal learning rate\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> <pre><code>2025-02-01 22:45:41.335 | INFO     | active_vision.core:lr_find:196 - Optimal learning rate: 0.0030199517495930195\n</code></pre> <p></p> <p>Not let's use the optimal learning rate to train the model end-to-end for 3 epochs and 1 epoch of head tuning.</p> <pre><code>al.train(epochs=10, lr=5e-3, head_tuning_epochs=3)\n</code></pre> <pre><code>2025-02-01 22:46:00.935 | INFO     | active_vision.core:train:207 - Training head for 3 epochs\n2025-02-01 22:46:00.936 | INFO     | active_vision.core:train:208 - Training model end-to-end for 10 epochs\n2025-02-01 22:46:00.936 | INFO     | active_vision.core:train:209 - Learning rate: 0.005 with one-cycle learning rate scheduler\n</code></pre> epoch train_loss valid_loss accuracy time 0 3.195328 1.852943 0.350000 00:01 1 2.282106 0.489679 0.850000 00:00 2 1.562541 0.170412 0.950000 00:00 <p></p> epoch train_loss valid_loss accuracy time 0 0.238324 0.192112 0.900000 00:01 1 0.227803 0.171933 0.950000 00:00 2 0.238925 0.134237 0.950000 00:00 3 0.181410 0.155849 0.950000 00:00 4 0.234001 0.228540 0.950000 00:00 5 0.229287 0.266996 0.950000 00:00 6 0.218886 0.201421 0.950000 00:00 7 0.199587 0.219203 0.950000 00:00 8 0.193316 0.216598 0.950000 00:00 9 0.176088 0.222188 0.950000 00:00 <p></p>"},{"location":"active_learning/#evaluate","title":"Evaluate","text":"<p>Now that we have a trained model, we can evaluate it on the evaluation set.</p> <pre><code>evaluation_df = pd.read_parquet(\"evaluation_samples.parquet\")\nevaluation_df\n</code></pre> filepath label 0 data/imagenette/val/n03394916/n03394916_32422.... French horn 1 data/imagenette/val/n03394916/n03394916_69132.... French horn 2 data/imagenette/val/n03394916/n03394916_33771.... French horn 3 data/imagenette/val/n03394916/n03394916_29940.... French horn 4 data/imagenette/val/n03394916/ILSVRC2012_val_0... French horn ... ... ... 3920 data/imagenette/val/n02979186/n02979186_27392.... cassette player 3921 data/imagenette/val/n02979186/n02979186_2742.JPEG cassette player 3922 data/imagenette/val/n02979186/n02979186_2312.JPEG cassette player 3923 data/imagenette/val/n02979186/n02979186_12822.... cassette player 3924 data/imagenette/val/n02979186/ILSVRC2012_val_0... cassette player <p>3925 rows \u00d7 2 columns</p> <pre><code>al.evaluate(evaluation_df, filepath_col=\"filepath\", label_col=\"label\")\n</code></pre> <pre><code>/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> <pre><code>2025-02-01 22:46:36.026 | INFO     | active_vision.core:evaluate:285 - Accuracy: 88.69%\n\n\n\n\n\n0.8868789808917198\n</code></pre> <p>That is a good start. ~88% accuracy is not bad for a first try with only 80 labeled samples. Let's see if we can improve it.</p> <p>Let's save the summary of the cycle.</p> <pre><code>al.summary()\n</code></pre> <pre><code>2025-02-01 22:46:58.694 | INFO     | active_vision.core:summary:578 - Saved results to cycle-1_20250201_224658_acc_88.69%_n_100.parquet\n</code></pre> name accuracy train_set_size valid_set_size dataset_size num_classes model pretrained loss_fn device seed batch_size image_size 0 cycle-1 0.886879 80 20 100 10 resnet18 True FlattenedLoss of CrossEntropyLoss() mps None 8 224 <p>The above will create a .parquet file with the summary of the cycle. This will be useful for tracking the progress of the active learning process.</p>"},{"location":"active_learning/#predict","title":"Predict","text":"<p>Using the model, we can predict the labels of the unlabeled samples and get the most impactful samples to label.</p> <pre><code>df = pd.read_parquet(\"unlabeled_samples.parquet\")\nfilepaths = df[\"filepath\"].tolist()\nlen(filepaths)\n</code></pre> <pre><code>9369\n</code></pre> <pre><code>pred_df = al.predict(filepaths, batch_size=128)\npred_df\n</code></pre> <pre><code>2025-02-01 22:48:06.456 | INFO     | active_vision.core:predict:216 - Running inference on 9369 samples\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> filepath pred_label pred_conf probs logits embeddings 0 data/imagenette/train/n03394916/n03394916_4437... French horn 0.9994 [0.0, 0.9994, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0... [-1.0149, 9.7605, 1.5589, 0.7921, -0.7977, -0.... [-2.2901, 2.3526, 6.4579, 4.2536, 2.6069, -0.7... 1 data/imagenette/train/n03394916/n03394916_4241... French horn 0.9999 [0.0, 0.9999, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0,... [0.1745, 12.1507, -0.4018, -1.8788, 3.0162, -2... [-2.0134, -2.8295, 5.1062, 2.4362, 3.5648, -0.... 2 data/imagenette/train/n03394916/n03394916_3880... French horn 0.5876 [0.0005, 0.5876, 0.0003, 0.1923, 0.0571, 0.006... [-2.0997, 5.0091, -2.5624, 3.8921, 2.677, 0.56... [-1.2764, -1.7355, -0.3358, 3.026, -0.7665, -2... 3 data/imagenette/train/n03394916/n03394916_2412... French horn 0.9960 [0.0, 0.996, 0.0013, 0.0006, 0.0018, 0.0001, 0... [-4.1342, 8.7273, 2.0689, 1.2724, 2.4322, -1.1... [-3.6719, 0.988, 3.3448, -2.0975, 2.0027, 2.49... 4 data/imagenette/train/n03394916/n03394916_1128... French horn 0.9870 [0.0001, 0.987, 0.0, 0.0113, 0.0012, 0.0004, 0... [-0.5818, 9.1891, -2.0218, 4.7223, 2.4576, 1.4... [3.1939, -1.9423, 1.637, 1.6741, 1.6321, -1.24... ... ... ... ... ... ... ... 9364 data/imagenette/train/n02979186/n02979186_8089... cassette player 0.9989 [0.0, 0.0, 0.9989, 0.0001, 0.0, 0.0, 0.0009, 0... [-0.1709, -1.1193, 10.3886, 1.022, -3.1766, -2... [-1.399, 0.6354, -0.2404, 0.1646, -0.2866, 4.4... 9365 data/imagenette/train/n02979186/n02979186_1944... cassette player 0.9975 [0.0, 0.0001, 0.9975, 0.0019, 0.0, 0.0002, 0.0... [-1.2339, -0.2522, 9.287, 3.0204, -2.5014, 0.7... [1.6241, 1.8808, 2.1247, 2.9433, -2.5819, 0.01... 9366 data/imagenette/train/n02979186/n02979186_1107... cassette player 0.9965 [0.0003, 0.0002, 0.9965, 0.0023, 0.0003, 0.0, ... [0.3064, -0.3192, 8.3105, 2.2191, 0.0921, -3.3... [-1.6214, -0.333, -0.5618, 5.5305, -2.7947, 1.... 9367 data/imagenette/train/n02979186/n02979186_2938... cassette player 0.9990 [0.0002, 0.0004, 0.999, 0.0002, 0.0, 0.0, 0.0,... [0.297, 1.1789, 9.0353, 0.3745, -1.4599, -1.22... [-3.9943, 2.4609, -0.4746, 5.7178, -1.1348, -2... 9368 data/imagenette/train/n02979186/n02979186_93.JPEG cassette player 0.9983 [0.0, 0.0, 0.9983, 0.0012, 0.0001, 0.0, 0.0002... [-0.7291, -0.914, 9.3241, 2.5684, -0.2463, -2.... [-0.3718, 2.5391, -0.3689, 5.6201, -0.3824, 0.... <p>9369 rows \u00d7 6 columns</p>"},{"location":"active_learning/#sample","title":"Sample","text":"<p>With the predicted labels, we can sample the most impactful samples to label using active learning strategies.</p> <p>For this example, we will use the <code>sample_combination</code> strategy to sample 50 samples from each strategy listed below in the specified proportions.</p> <pre><code>samples = al.sample_combination(\n    pred_df,\n    num_samples=50,\n    combination={\n        \"least-confidence\": 0.4,\n        \"ratio-of-confidence\": 0.2,\n        \"entropy\": 0.2,\n        \"model-based-outlier\": 0.1,\n        \"random\": 0.1,\n    },\n)\n\nsamples\n</code></pre> <pre><code>2025-02-01 22:48:54.961 | INFO     | active_vision.core:sample_combination:498 - Using combination sampling to get 50 samples\n2025-02-01 22:48:54.965 | INFO     | active_vision.core:sample_uncertain:305 - Using least confidence strategy to get top 20 samples\n2025-02-01 22:48:54.981 | INFO     | active_vision.core:sample_uncertain:328 - Using ratio of confidence strategy to get top 10 samples\n2025-02-01 22:48:55.030 | INFO     | active_vision.core:sample_uncertain:342 - Using entropy strategy to get top 10 samples\n/Users/dnth/Desktop/active-vision/src/active_vision/core.py:345: RuntimeWarning: divide by zero encountered in log2\n  df.loc[:, \"score\"] = df[\"probs\"].apply(lambda x: -np.sum(x * np.log2(x)))\n/Users/dnth/Desktop/active-vision/src/active_vision/core.py:345: RuntimeWarning: invalid value encountered in multiply\n  df.loc[:, \"score\"] = df[\"probs\"].apply(lambda x: -np.sum(x * np.log2(x)))\n2025-02-01 22:48:55.067 | INFO     | active_vision.core:sample_diverse:388 - Using model-based outlier strategy to get top 5 samples\n2025-02-01 22:48:55.067 | INFO     | active_vision.core:predict:216 - Running inference on 20 samples\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> <pre><code>2025-02-01 22:48:55.347 | INFO     | active_vision.core:sample_random:460 - Sampling 5 random samples\n</code></pre> filepath strategy score pred_label pred_conf probs logits embeddings 0 data/imagenette/train/n02979186/n02979186_1337... least-confidence 0.7832 church 0.2168 [0.1246, 0.1754, 0.1861, 0.0186, 0.2168, 0.022... [1.1863, 1.5285, 1.5874, -0.7142, 1.7403, -0.5... [0.2377, -1.946, 0.2599, 2.6317, 0.0457, -0.39... 1 data/imagenette/train/n03417042/n03417042_6809... least-confidence 0.7671 English springer 0.2329 [0.2329, 0.0563, 0.0152, 0.1935, 0.1016, 0.165... [1.6971, 0.2781, -1.0305, 1.5121, 0.8675, 1.35... [-3.1134, -1.0297, -2.949, -0.0299, -2.6318, -... 2 data/imagenette/train/n03417042/n03417042_1228... least-confidence 0.7520 garbage truck 0.2480 [0.0136, 0.0788, 0.1113, 0.2256, 0.134, 0.248,... [-1.3881, 0.3689, 0.7144, 1.4204, 0.8993, 1.51... [-3.2014, -0.3192, 0.4875, 1.5605, -2.9503, 0.... 3 data/imagenette/train/n03445777/ILSVRC2012_val... least-confidence 0.7489 parachute 0.2511 [0.0523, 0.0888, 0.1879, 0.2397, 0.0256, 0.048... [0.2414, 0.771, 1.5211, 1.7646, -0.4716, 0.173... [-2.1577, -0.6424, 0.7163, 4.899, 2.0297, -0.0... 4 data/imagenette/train/n01440764/n01440764_6118... least-confidence 0.7468 parachute 0.2532 [0.2469, 0.1803, 0.015, 0.0427, 0.0, 0.0004, 0... [2.4125, 2.098, -0.3905, 0.6568, -6.4931, -4.0... [2.3019, -0.1646, 0.0037, 4.9036, 0.2177, -0.8... 5 data/imagenette/train/n03417042/n03417042_3796... least-confidence 0.7390 church 0.2610 [0.0097, 0.0347, 0.2573, 0.0808, 0.261, 0.1535... [-1.1992, 0.0708, 2.0745, 0.9159, 2.0887, 1.55... [-2.1991, -2.0034, -0.235, 2.4318, 0.3569, -0.... 6 data/imagenette/train/n03425413/n03425413_1459... least-confidence 0.7385 chain saw 0.2615 [0.2496, 0.0804, 0.0628, 0.2615, 0.0127, 0.047... [1.951, 0.8179, 0.5707, 1.9976, -1.026, 0.2976... [-2.4328, -1.083, -0.361, 3.5946, 0.9601, -2.1... 7 data/imagenette/train/n03445777/n03445777_2207... least-confidence 0.7263 parachute 0.2737 [0.019, 0.1925, 0.1283, 0.0205, 0.0706, 0.0071... [-0.5736, 1.7433, 1.3381, -0.4974, 0.7405, -1.... [0.9713, -3.2046, -0.5145, 2.0419, 0.7177, -0.... 8 data/imagenette/train/n02102040/n02102040_1076... least-confidence 0.7260 chain saw 0.2740 [0.2575, 0.1359, 0.0061, 0.274, 0.0956, 0.001,... [2.2694, 1.6301, -1.4805, 2.3315, 1.2792, -3.2... [2.5813, -0.1416, -2.0389, -2.2112, -1.5039, 3... 9 data/imagenette/train/n03000684/n03000684_1466... least-confidence 0.7233 gas pump 0.2767 [0.0088, 0.1782, 0.0831, 0.1853, 0.0177, 0.040... [-1.5001, 1.5067, 0.7434, 1.546, -0.8016, 0.02... [-1.8619, -0.0667, 1.8241, -3.3802, 1.3863, 2.... 10 data/imagenette/train/n03425413/n03425413_1864... least-confidence 0.7206 garbage truck 0.2794 [0.0078, 0.0121, 0.2249, 0.057, 0.1745, 0.2794... [-1.3753, -0.9285, 1.9904, 0.6176, 1.7364, 2.2... [0.5058, -1.2274, -1.1775, 0.4627, 0.0353, -0.... 11 data/imagenette/train/n03417042/n03417042_1223... least-confidence 0.7168 gas pump 0.2832 [0.025, 0.2146, 0.0005, 0.2588, 0.016, 0.1269,... [-0.9034, 1.2471, -4.8891, 1.4342, -1.3511, 0.... [1.5009, -3.5794, 0.7903, -4.7695, 0.7535, 1.3... 12 data/imagenette/train/n01440764/n01440764_5668... least-confidence 0.7080 parachute 0.2920 [0.0844, 0.2893, 0.0014, 0.073, 0.0001, 0.0007... [1.9209, 3.153, -2.2034, 1.7755, -5.193, -2.89... [1.7147, -3.039, -2.7734, 4.8007, -2.612, -1.4... 13 data/imagenette/train/n03425413/n03425413_88.JPEG least-confidence 0.7071 chain saw 0.2929 [0.0103, 0.0188, 0.0715, 0.2929, 0.0373, 0.276... [-1.1609, -0.5619, 0.7725, 2.1827, 0.1219, 2.1... [-1.8984, -1.801, -0.5466, 0.1875, -0.2696, -2... 14 data/imagenette/train/n03425413/n03425413_6234... least-confidence 0.7045 cassette player 0.2955 [0.0036, 0.0121, 0.2955, 0.2136, 0.0019, 0.001... [-0.5274, 0.6789, 3.8764, 3.5516, -1.1846, -1.... [-1.1586, -1.5979, 0.6346, 4.4901, 0.9681, -2.... 15 data/imagenette/train/n03417042/n03417042_1668... least-confidence 0.7036 chain saw 0.2964 [0.0254, 0.0108, 0.1052, 0.2964, 0.0089, 0.291... [0.6178, -0.2364, 2.0373, 3.0728, -0.438, 3.05... [-1.9726, -4.8946, 0.8208, 2.5173, -3.8419, -2... 16 data/imagenette/train/n03445777/n03445777_4247... least-confidence 0.7012 golf ball 0.2988 [0.0429, 0.0009, 0.258, 0.0017, 0.2062, 0.0048... [1.4205, -2.437, 3.2146, -1.82, 2.9905, -0.761... [-1.1034, -0.4575, -0.8034, 3.1827, -0.7845, -... 17 data/imagenette/train/n03445777/n03445777_646.... least-confidence 0.7008 cassette player 0.2992 [0.0756, 0.0503, 0.2992, 0.2987, 0.006, 0.0125... [1.1265, 0.7181, 2.5015, 2.5, -1.4094, -0.6715... [-2.646, 0.4589, 0.6154, 3.3417, -0.0063, -1.9... 18 data/imagenette/train/n02979186/n02979186_9394... least-confidence 0.6984 church 0.3016 [0.2609, 0.0025, 0.0002, 0.0618, 0.3016, 0.004... [2.7936, -1.8698, -4.2219, 1.3531, 2.9384, -1.... [1.2048, -4.0506, -1.426, 1.0096, 0.5019, -0.3... 19 data/imagenette/train/n03417042/n03417042_1764... least-confidence 0.6982 chain saw 0.3018 [0.0148, 0.0047, 0.1673, 0.3018, 0.0515, 0.200... [-0.9573, -2.1062, 1.4707, 2.0609, 0.2926, 1.6... [-4.4805, -0.7656, 2.3438, -2.386, -1.4532, -1... 20 data/imagenette/train/n03028079/n03028079_236.... ratio-of-confidence 0.9980 church 0.4982 [0.0012, 0.0002, 0.0009, 0.0004, 0.4982, 0.001... [0.1461, -1.7966, -0.1312, -0.9224, 6.1598, -0... [-1.9158, 0.0293, -2.9185, 5.4466, 1.4893, -4.... 21 data/imagenette/train/n01440764/n01440764_8849... ratio-of-confidence 0.9965 French horn 0.3182 [0.0008, 0.3182, 0.0064, 0.1057, 0.0001, 0.001... [-2.4424, 3.6063, -0.2949, 2.5045, -4.2242, -2... [1.7128, 1.7141, 0.4452, 4.5691, -3.717, -0.81... 22 data/imagenette/train/n03425413/n03425413_2131... ratio-of-confidence 0.9951 gas pump 0.4921 [0.0021, 0.0002, 0.0014, 0.0006, 0.4897, 0.002... [-0.2209, -2.4339, -0.5894, -1.4373, 5.2495, 0... [1.8346, -2.7913, 1.1247, 3.9242, 3.2139, -1.9... 23 data/imagenette/train/n03417042/n03417042_1025... ratio-of-confidence 0.9949 garbage truck 0.4712 [0.0, 0.0367, 0.0177, 0.4688, 0.0006, 0.4712, ... [-5.5346, 2.1603, 1.4321, 4.7075, -1.9854, 4.7... [-2.0354, -0.3725, 3.4936, -1.2543, -1.7814, -... 24 data/imagenette/train/n03445777/n03445777_8544... ratio-of-confidence 0.9929 golf ball 0.4791 [0.0019, 0.0, 0.4757, 0.0003, 0.0244, 0.0002, ... [0.2898, -4.0663, 5.7935, -1.5026, 2.8246, -1.... [-1.6029, -0.0789, -1.3203, 2.3646, -1.7308, -... 25 data/imagenette/train/n02979186/n02979186_1028... ratio-of-confidence 0.9928 cassette player 0.4292 [0.0017, 0.0804, 0.4292, 0.4261, 0.008, 0.0001... [-1.9055, 1.9553, 3.6303, 3.6232, -0.347, -5.0... [0.661, -0.879, 0.9711, 6.3615, -1.8835, 0.572... 26 data/imagenette/train/n02979186/n02979186_174.... ratio-of-confidence 0.9928 gas pump 0.4728 [0.0016, 0.001, 0.4694, 0.0023, 0.0103, 0.0006... [-0.8054, -1.2681, 4.8906, -0.434, 1.0697, -1.... [-2.2132, 1.2331, 0.0182, 3.1745, 1.2983, -1.4... 27 data/imagenette/train/n03417042/n03417042_7005... ratio-of-confidence 0.9905 garbage truck 0.4836 [0.0094, 0.0002, 0.479, 0.0178, 0.0004, 0.4836... [0.9137, -2.959, 4.8444, 1.5534, -2.1481, 4.85... [-5.0773, -1.4379, 0.4747, 2.3539, -0.0054, -0... 28 data/imagenette/train/n03028079/n03028079_7073... ratio-of-confidence 0.9902 parachute 0.3277 [0.1374, 0.0006, 0.1855, 0.0042, 0.3245, 0.000... [3.0215, -2.4062, 3.3213, -0.4689, 3.8805, -2.... [-2.5169, -0.1161, -2.0849, 6.913, 0.1524, -3.... 29 data/imagenette/train/n01440764/n01440764_3428... ratio-of-confidence 0.9895 tench 0.4676 [0.0179, 0.0016, 0.0007, 0.0002, 0.0, 0.0001, ... [2.3502, -0.0881, -0.8439, -2.1083, -6.3656, -... [2.0489, -0.5436, -1.8257, 8.6326, -2.1322, -1... 30 data/imagenette/train/n03445777/n03445777_4554... entropy 0.8296 golf ball 0.3049 [0.0693, 0.081, 0.0229, 0.1553, 0.1212, 0.1887... [0.4616, 0.6175, -0.6483, 1.2682, 1.0204, 1.46... [0.8206, -0.299, 0.5261, 4.4358, 1.3322, -2.03... 31 data/imagenette/train/n03425413/n03425413_9229... entropy 0.8130 cassette player 0.3564 [0.1393, 0.0395, 0.3564, 0.1581, 0.0049, 0.012... [1.1223, -0.138, 2.062, 1.2494, -2.2206, -1.30... [0.5329, -0.7068, 1.3603, 0.652, 0.0198, -1.40... 32 data/imagenette/train/n03425413/n03425413_287.... entropy 0.7982 cassette player 0.3625 [0.1304, 0.0647, 0.3625, 0.0102, 0.007, 0.0077... [1.5995, 0.8984, 2.6221, -0.9448, -1.3237, -1.... [-0.0355, 1.2429, 2.0399, 1.95, -0.4611, -2.16... 33 data/imagenette/train/n03417042/n03417042_908.... entropy 0.7812 French horn 0.3538 [0.0043, 0.3538, 0.1463, 0.149, 0.1439, 0.1248... [-2.7491, 1.661, 0.7778, 0.7963, 0.7618, 0.618... [-7.2806, -0.9896, 1.8656, -2.0554, -3.9013, -... 34 data/imagenette/train/n02979186/n02979186_465.... entropy 0.7801 cassette player 0.3180 [0.01, 0.0162, 0.318, 0.178, 0.243, 0.041, 0.0... [-1.1959, -0.7156, 2.2638, 1.6833, 1.9948, 0.2... [-1.0496, -0.4233, -0.2356, 1.7336, 0.0313, -1... 35 data/imagenette/train/n03417042/n03417042_5249... entropy 0.7770 gas pump 0.3602 [0.2176, 0.0115, 0.075, 0.0565, 0.0042, 0.1158... [2.2736, -0.6667, 1.2081, 0.9261, -1.6621, 1.6... [-2.3321, -1.439, 0.5272, -1.0743, 0.0884, 1.3... 36 data/imagenette/train/n02979186/n02979186_603.... entropy 0.7659 parachute 0.3955 [0.0246, 0.0061, 0.105, 0.1808, 0.058, 0.0508,... [-0.1705, -1.567, 1.2804, 1.8236, 0.6872, 0.55... [-1.8714, -1.0384, 0.5632, 5.8721, -1.3883, -2... 37 data/imagenette/train/n03000684/n03000684_1852... entropy 0.7570 cassette player 0.3107 [0.0748, 0.0867, 0.3107, 0.2456, 0.0107, 0.001... [0.1843, 0.3323, 1.609, 1.3735, -1.7552, -3.56... [0.7092, 4.0615, 0.0916, 2.6069, -0.8592, 1.58... 38 data/imagenette/train/n03417042/n03417042_4126... entropy 0.7549 gas pump 0.3585 [0.013, 0.0954, 0.153, 0.0395, 0.1221, 0.1953,... [-0.5105, 1.4799, 1.9525, 0.598, 1.7271, 2.196... [-2.1074, -0.719, 0.3273, -4.9685, -0.2971, 0.... 39 data/imagenette/train/n02979186/n02979186_1288... entropy 0.7484 English springer 0.4436 [0.4436, 0.1239, 0.1386, 0.0856, 0.0053, 0.019... [3.0178, 1.7421, 1.8544, 1.3729, -1.4053, -0.1... [-1.5024, -1.7685, -1.1186, 3.3219, -0.2236, -... 40 data/imagenette/train/n03394916/n03394916_2325... model-based-outlier 0.9000 parachute 0.4584 [0.0077, 0.4082, 0.0652, 0.0305, 0.0034, 0.002... [0.0285, 3.9961, 2.1624, 1.4036, -0.798, -1.07... [-1.8628, 0.4449, 2.5449, 4.2519, 0.3109, -0.2... 41 data/imagenette/train/n03888257/n03888257_3037... model-based-outlier 0.9000 parachute 0.9985 [0.0002, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0... [1.795, 1.3068, -5.9289, 0.588, -0.2612, 0.439... [-0.5929, -1.6006, 0.4943, -1.2933, 2.7818, -0... 42 data/imagenette/train/n02102040/n02102040_3157... model-based-outlier 0.9000 English springer 0.9990 [0.999, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0002,... [10.0692, 0.2787, -1.2835, 0.6064, -1.1916, -0... [2.3258, -3.616, -0.5858, 6.3145, 1.105, -0.14... 43 data/imagenette/train/n03394916/n03394916_4728... model-based-outlier 0.9000 parachute 0.4831 [0.0488, 0.2531, 0.0026, 0.0485, 0.0044, 0.025... [1.0755, 2.7207, -1.8696, 1.0683, -1.3336, 0.4... [0.1506, -1.9805, 0.9849, 3.5843, -0.0043, -1.... 44 data/imagenette/train/n03417042/n03417042_1021... model-based-outlier 0.9000 garbage truck 0.9537 [0.0086, 0.0002, 0.0075, 0.0023, 0.0007, 0.953... [2.0034, -1.9979, 1.8706, 0.71, -0.4847, 6.717... [-3.3996, -1.5936, 0.7646, 2.4388, -1.7322, -2... 45 data/imagenette/train/n03417042/n03417042_1858... random 0.0000 garbage truck 0.7858 [0.0143, 0.0061, 0.0087, 0.1633, 0.0015, 0.785... [0.3009, -0.5477, -0.1979, 2.7391, -1.9379, 4.... [-3.5253, -2.8105, 3.3649, -1.5904, -2.0809, -... 46 data/imagenette/train/n03394916/n03394916_2376... random 0.0000 French horn 1.0000 [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ... [-3.3366, 12.358, 0.1247, 0.7122, 1.0722, -2.4... [-0.7454, -2.0169, 5.2131, 1.7518, 1.3361, 0.4... 47 data/imagenette/train/n01440764/n01440764_1166... random 0.0000 tench 0.9899 [0.0038, 0.0015, 0.0001, 0.0002, 0.0, 0.0, 0.0... [2.0583, 1.1105, -1.2277, -0.7113, -5.8862, -2... [4.0684, -1.9906, -0.8653, 5.5249, -1.2073, -0... 48 data/imagenette/train/n02979186/n02979186_1834... random 0.0000 cassette player 0.9763 [0.0001, 0.0, 0.9763, 0.0001, 0.0009, 0.0, 0.0... [-0.2952, -2.528, 8.5269, -0.8405, 1.5539, -1.... [-1.0581, 0.6868, 0.1566, 2.4419, 1.0955, 0.19... 49 data/imagenette/train/n03888257/n03888257_1158... random 0.0000 parachute 1.0000 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ... [0.2342, -3.6737, -3.615, -4.0797, -0.533, 1.2... [-1.6263, 2.0753, -2.3862, -0.6846, -1.6283, -..."},{"location":"active_learning/#label","title":"Label","text":"<p>Let's label the samples and save them to a parquet file named <code>combination.parquet</code>.</p> <pre><code>al.label(samples, output_filename=\"combination.parquet\")\n</code></pre> <pre><code>2025-02-01 22:50:11.038 | INFO     | active_vision.core:label:612 - Launching labeling interface for 50 samples\n\n\n* Running on local URL:  http://127.0.0.1:7860\n\nTo create a public link, set `share=True` in `launch()`.\n</code></pre> <p></p> <p>The Gradio interface will open up and you can label the samples. You could also see the confidence of the model for each sample to debug the model.</p> <p>We can inspect the samples we just labeled.</p> <pre><code>labeled_df = pd.read_parquet(\"combination.parquet\")\n\nlabeled_df\n</code></pre> filepath label 0 data/imagenette/train/n02979186/n02979186_1337... cassette player 1 data/imagenette/train/n03417042/n03417042_6809... garbage truck 2 data/imagenette/train/n03417042/n03417042_1228... garbage truck 3 data/imagenette/train/n03445777/ILSVRC2012_val... golf ball 4 data/imagenette/train/n01440764/n01440764_6118... tench 5 data/imagenette/train/n03417042/n03417042_3796... garbage truck 6 data/imagenette/train/n03425413/n03425413_1459... gas pump 7 data/imagenette/train/n03445777/n03445777_2207... golf ball 8 data/imagenette/train/n02102040/n02102040_1076... English springer 9 data/imagenette/train/n03000684/n03000684_1466... chain saw 10 data/imagenette/train/n03425413/n03425413_1864... gas pump 11 data/imagenette/train/n03417042/n03417042_1223... garbage truck 12 data/imagenette/train/n01440764/n01440764_5668... tench 13 data/imagenette/train/n03425413/n03425413_88.JPEG gas pump 14 data/imagenette/train/n03425413/n03425413_6234... gas pump 15 data/imagenette/train/n03417042/n03417042_1668... garbage truck 16 data/imagenette/train/n03445777/n03445777_4247... golf ball 17 data/imagenette/train/n03445777/n03445777_646.... golf ball 18 data/imagenette/train/n02979186/n02979186_9394... cassette player 19 data/imagenette/train/n03417042/n03417042_1764... garbage truck 20 data/imagenette/train/n03028079/n03028079_236.... church 21 data/imagenette/train/n01440764/n01440764_8849... tench 22 data/imagenette/train/n03425413/n03425413_2131... gas pump 23 data/imagenette/train/n03417042/n03417042_1025... garbage truck 24 data/imagenette/train/n03445777/n03445777_8544... golf ball 25 data/imagenette/train/n02979186/n02979186_1028... cassette player 26 data/imagenette/train/n02979186/n02979186_174.... cassette player 27 data/imagenette/train/n03417042/n03417042_7005... garbage truck 28 data/imagenette/train/n03028079/n03028079_7073... church 29 data/imagenette/train/n01440764/n01440764_3428... tench 30 data/imagenette/train/n03445777/n03445777_4554... golf ball 31 data/imagenette/train/n03425413/n03425413_9229... gas pump 32 data/imagenette/train/n03425413/n03425413_287.... gas pump 33 data/imagenette/train/n03417042/n03417042_908.... garbage truck 34 data/imagenette/train/n02979186/n02979186_465.... gas pump 35 data/imagenette/train/n03417042/n03417042_5249... garbage truck 36 data/imagenette/train/n03000684/n03000684_1852... chain saw 37 data/imagenette/train/n03417042/n03417042_4126... garbage truck 38 data/imagenette/train/n02979186/n02979186_1288... cassette player 39 data/imagenette/train/n03394916/n03394916_2325... French horn 40 data/imagenette/train/n03888257/n03888257_3037... parachute 41 data/imagenette/train/n02102040/n02102040_3157... English springer 42 data/imagenette/train/n03394916/n03394916_4728... French horn 43 data/imagenette/train/n03417042/n03417042_1021... garbage truck 44 data/imagenette/train/n03417042/n03417042_1858... garbage truck 45 data/imagenette/train/n03394916/n03394916_2376... French horn 46 data/imagenette/train/n01440764/n01440764_1166... tench 47 data/imagenette/train/n02979186/n02979186_1834... cassette player 48 data/imagenette/train/n03888257/n03888257_1158... parachute"},{"location":"active_learning/#add-to-train-set","title":"Add to train set","text":"<p>Now that we have labeled the samples, we can add them to the train set and save it to a parquet file named <code>active_labeled.parquet</code>.</p> <pre><code>al.add_to_dataset(labeled_df, output_filename=\"active_labeled.parquet\")\n</code></pre> <pre><code>2025-02-01 22:55:13.929 | INFO     | active_vision.core:add_to_dataset:1060 - Adding 49 samples to dataset\n2025-02-01 22:55:13.932 | INFO     | active_vision.core:add_to_dataset:1068 - Saved dataset to active_labeled.parquet\n</code></pre>"},{"location":"active_learning/#repeat","title":"Repeat","text":"<p>Congratulations! You have completed the first cycle of active learning. We now have a small dataset and a trained model. Now whats left is to repeat the process of predicting, sampling, labeling, and adding to the train set until we have a good model.</p>"},{"location":"active_learning/#tracking-progress","title":"Tracking Progress","text":"<p>You can track the progress of the active learning process by inspecting the .parquet files saved when running the <code>al.summary()</code> function.</p> <p>In this example, I ran 4 cycles of active learning which resulted in the following files:</p> <ul> <li><code>cycle-1_20250201_224658_acc_88.69%_n_100.parquet</code></li> <li><code>cycle-2_20250201_225913_acc_92.18%_n_149.parquet</code></li> <li><code>cycle-3_20250201_232340_acc_93.45%_n_195.parquet</code></li> <li><code>cycle-4_20250201_233055_acc_94.52%_n_243.parquet</code></li> </ul> <p>The name of the file contains the cycle name, the date, the accuracy, and the number of labeled samples.</p> <pre><code>import glob\nimport pandas as pd\n\n# Get all parquet files with 'cycle' in the name\ncycle_files = glob.glob(\"cycle-*.parquet\")\n\n# Read and concatenate all cycle files\nall_cycles_df = pd.concat([pd.read_parquet(f) for f in cycle_files], ignore_index=True)\n\nall_cycles_df = all_cycles_df.sort_values(by=\"name\", ascending=True)\nall_cycles_df\n</code></pre> name accuracy train_set_size valid_set_size dataset_size num_classes model pretrained loss_fn device seed batch_size image_size 1 cycle-1 0.886879 80 20 100 10 resnet18 True FlattenedLoss of CrossEntropyLoss() mps None 8 224 0 cycle-2 0.921783 120 29 149 10 resnet18 True FlattenedLoss of CrossEntropyLoss() mps None 8 224 3 cycle-3 0.934522 156 39 195 10 resnet18 True FlattenedLoss of CrossEntropyLoss() mps None 8 224 2 cycle-4 0.945223 195 48 243 10 resnet18 True FlattenedLoss of CrossEntropyLoss() mps None 8 224 <pre><code>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(10, 6))\nsns.lineplot(data=all_cycles_df, x='dataset_size', y='accuracy', marker='o')\n\nplt.title('Model Accuracy vs Dataset Size')\nplt.xlabel('Number of Images')\nplt.ylabel('Accuracy')\n\nplt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n\nplt.grid(True, linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p>"},{"location":"preparing_data/","title":"Preparing Data","text":""},{"location":"preparing_data/#download-the-dataset","title":"Download the dataset","text":"<p>In this example, we will use the Imagenette dataset to demonstrate how to prepare data for active learning.</p> <p>Before we start, we need to prepare 3 sets of data:</p> <ul> <li>Initial samples: A dataset of labeled images to train an initial model. If you don't have any labeled data, you can label some images yourself.</li> <li>Unlabeled samples: A dataset of unlabeled images. We will continuously sample from this set using active learning strategies.</li> <li>Evaluation samples: A dataset of labeled images. We will use this set to evaluate the performance of the model. This is the test set, DO NOT use it for active learning. Split this out in the beginning.</li> </ul> <p>We will use the Imagenette dataset as a working example in this notebook.</p> <p>First, lets download the dataset and extract it.</p> <pre><code>!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n!tar -xvzf imagenette2.tgz\n!mv imagenette2 data/imagenette\n!rm imagenette2.tgz\n</code></pre>"},{"location":"preparing_data/#load-the-dataset","title":"Load the dataset","text":"<p><code>active-vision</code> currently supports datasets in a pandas dataframe format. The dataframe should have at least 2 columns: <code>filepath</code> and <code>label</code>.</p> <pre><code>from fastai.vision.all import get_image_files\n\npath = \"data/imagenette/train\"\nimage_files = get_image_files(path)\nlen(image_files)\n</code></pre> <pre><code>9469\n</code></pre> <pre><code>lbl_dict = {\n    \"n01440764\": \"tench\",\n    \"n02102040\": \"English springer\",\n    \"n02979186\": \"cassette player\",\n    \"n03000684\": \"chain saw\",\n    \"n03028079\": \"church\",\n    \"n03394916\": \"French horn\",\n    \"n03417042\": \"garbage truck\",\n    \"n03425413\": \"gas pump\",\n    \"n03445777\": \"golf ball\",\n    \"n03888257\": \"parachute\",\n}\n</code></pre> <pre><code>import pandas as pd\n\n# Create a dataframe with the filepath and label from parent directory\nlabels = [str(path.parts[-2]) for path in image_files]\n\n# Map the labels to the label dictionary\nlabels = [lbl_dict[lbl] for lbl in labels]\n\ndf = pd.DataFrame({\"filepath\": [str(path) for path in image_files], \"label\": labels})\n\ndf\n</code></pre> filepath label 0 data/imagenette/train/n03394916/ILSVRC2012_val_00046669.JPEG French horn 1 data/imagenette/train/n03394916/n03394916_58454.JPEG French horn 2 data/imagenette/train/n03394916/n03394916_32588.JPEG French horn 3 data/imagenette/train/n03394916/n03394916_33663.JPEG French horn 4 data/imagenette/train/n03394916/n03394916_27948.JPEG French horn ... ... ... 9464 data/imagenette/train/n02979186/n02979186_8089.JPEG cassette player 9465 data/imagenette/train/n02979186/n02979186_19444.JPEG cassette player 9466 data/imagenette/train/n02979186/n02979186_11074.JPEG cassette player 9467 data/imagenette/train/n02979186/n02979186_2938.JPEG cassette player 9468 data/imagenette/train/n02979186/n02979186_93.JPEG cassette player <p>9469 rows \u00d7 2 columns</p>"},{"location":"preparing_data/#initial-samples","title":"Initial samples","text":"<p>As an initial step, we will randomly sample 10 samples from each class. We will use these samples to kickstart the active learning process.</p> <pre><code>initial_samples = (\n    df.groupby(\"label\")\n    .apply(lambda x: x.sample(n=10, random_state=316))\n    .reset_index(drop=True)\n)\n\ninitial_samples\n</code></pre> <pre><code>/var/folders/9y/5mpk58851fq38f8ljx2svvnm0000gn/T/ipykernel_22109/414664958.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda x: x.sample(n=10, random_state=316))\n</code></pre> filepath label 0 data/imagenette/train/n02102040/n02102040_2788.JPEG English springer 1 data/imagenette/train/n02102040/n02102040_3759.JPEG English springer 2 data/imagenette/train/n02102040/n02102040_1916.JPEG English springer 3 data/imagenette/train/n02102040/n02102040_6147.JPEG English springer 4 data/imagenette/train/n02102040/n02102040_403.JPEG English springer ... ... ... 95 data/imagenette/train/n01440764/n01440764_10043.JPEG tench 96 data/imagenette/train/n01440764/n01440764_31535.JPEG tench 97 data/imagenette/train/n01440764/n01440764_12848.JPEG tench 98 data/imagenette/train/n01440764/n01440764_3997.JPEG tench 99 data/imagenette/train/n01440764/n01440764_29788.JPEG tench <p>100 rows \u00d7 2 columns</p> <p>Let's check the distribution of the labels.</p> <pre><code>initial_samples[\"label\"].value_counts()\n</code></pre> <pre><code>label\nEnglish springer    10\nFrench horn         10\ncassette player     10\nchain saw           10\nchurch              10\ngarbage truck       10\ngas pump            10\ngolf ball           10\nparachute           10\ntench               10\nName: count, dtype: int64\n</code></pre> <p>And save it to a parquet file.</p> <pre><code>initial_samples.to_parquet(\"initial_samples.parquet\")\n</code></pre>"},{"location":"preparing_data/#unlabeled-samples","title":"Unlabeled samples","text":"<p>For the remaining samples, we will use them as unlabeled samples. We will sample from these samples using active learning strategies.</p> <pre><code># Get the remaining samples by using pd.Index.difference\nremaining_samples = df[~df.index.isin(initial_samples.index)].reset_index(drop=True)\nremaining_samples\n</code></pre> filepath label 0 data/imagenette/train/n03394916/n03394916_4437.JPEG French horn 1 data/imagenette/train/n03394916/n03394916_42413.JPEG French horn 2 data/imagenette/train/n03394916/n03394916_38808.JPEG French horn 3 data/imagenette/train/n03394916/n03394916_24128.JPEG French horn 4 data/imagenette/train/n03394916/n03394916_11289.JPEG French horn ... ... ... 9364 data/imagenette/train/n02979186/n02979186_8089.JPEG cassette player 9365 data/imagenette/train/n02979186/n02979186_19444.JPEG cassette player 9366 data/imagenette/train/n02979186/n02979186_11074.JPEG cassette player 9367 data/imagenette/train/n02979186/n02979186_2938.JPEG cassette player 9368 data/imagenette/train/n02979186/n02979186_93.JPEG cassette player <p>9369 rows \u00d7 2 columns</p> <pre><code>remaining_samples.to_parquet(\"unlabeled_samples.parquet\")\n</code></pre>"},{"location":"preparing_data/#evaluation-samples","title":"Evaluation samples","text":"<p>Now let's create the evaluation samples which will be used to evaluate the performance of the model. We will use the validation set from the Imagenette dataset as the evaluation set.</p> <pre><code>path = \"data/imagenette/val\"\nimage_files = get_image_files(path)\nlen(image_files)\n</code></pre> <pre><code>3925\n</code></pre> <pre><code>labels = [str(path.parts[-2]) for path in image_files]\n\n# Map the labels to the label dictionary\nlabels = [lbl_dict[lbl] for lbl in labels]\n\nevaluation_samples = pd.DataFrame(\n    {\"filepath\": [str(path) for path in image_files], \"label\": labels}\n)\n\nevaluation_samples\n</code></pre> filepath label 0 data/imagenette/val/n03394916/n03394916_32422.JPEG French horn 1 data/imagenette/val/n03394916/n03394916_69132.JPEG French horn 2 data/imagenette/val/n03394916/n03394916_33771.JPEG French horn 3 data/imagenette/val/n03394916/n03394916_29940.JPEG French horn 4 data/imagenette/val/n03394916/ILSVRC2012_val_00033682.JPEG French horn ... ... ... 3920 data/imagenette/val/n02979186/n02979186_27392.JPEG cassette player 3921 data/imagenette/val/n02979186/n02979186_2742.JPEG cassette player 3922 data/imagenette/val/n02979186/n02979186_2312.JPEG cassette player 3923 data/imagenette/val/n02979186/n02979186_12822.JPEG cassette player 3924 data/imagenette/val/n02979186/ILSVRC2012_val_00042982.JPEG cassette player <p>3925 rows \u00d7 2 columns</p> <pre><code>evaluation_samples.to_parquet(\"evaluation_samples.parquet\")\n</code></pre> <p>We are now ready to start the active learning process.</p>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#introduction","title":"Introduction","text":"<p>This notebook will guide you through the basic steps to get started with Active Vision.</p> <p>By the end of this notebook, you will be able to:</p> <ul> <li>Understand the basic workflow of active learning</li> <li>Understand the basic components of Active Vision</li> <li>Understand how to use Active Vision to train a model</li> <li>Understand how to use Active Vision to iteratively improve your dataset</li> </ul> <p>Before we start, we need to prepare 3 sets of data:</p> <ul> <li>Initial samples: A dataset of labeled images to train an initial model. If you don't have any labeled data, you can label some images yourself.</li> <li>Unlabeled samples: A dataset of unlabeled images. We will continuously sample from this set using active learning strategies.</li> <li>Evaluation samples: A dataset of labeled images. We will use this set to evaluate the performance of the model. This is the test set, DO NOT use it for active learning. Split this out in the beginning.</li> </ul> <p>We will use the Imagenette dataset as a working example in this notebook.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>!pip install active-vision\n</code></pre>"},{"location":"quickstart/#download-the-dataset","title":"Download the dataset","text":"<p>First, lets download the dataset and extract it.</p> <pre><code>!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n!tar -xvzf imagenette2.tgz\n!mkdir data\n!mv imagenette2 data/imagenette\n!rm imagenette2.tgz\n</code></pre>"},{"location":"quickstart/#load-the-dataset","title":"Load the dataset","text":"<p><code>active-vision</code> currently supports datasets in a pandas dataframe format. The dataframe should have at least 2 columns: <code>filepath</code> and <code>label</code>.</p> <pre><code>from fastai.vision.all import get_image_files\n\npath = \"data/imagenette/train\"\nimage_files = get_image_files(path)\nlen(image_files)\n</code></pre> <pre><code>9469\n</code></pre> <pre><code>lbl_dict = {\n    \"n01440764\": \"tench\",\n    \"n02102040\": \"English springer\",\n    \"n02979186\": \"cassette player\",\n    \"n03000684\": \"chain saw\",\n    \"n03028079\": \"church\",\n    \"n03394916\": \"French horn\",\n    \"n03417042\": \"garbage truck\",\n    \"n03425413\": \"gas pump\",\n    \"n03445777\": \"golf ball\",\n    \"n03888257\": \"parachute\",\n}\n</code></pre> <pre><code>import pandas as pd\n\n# Create a dataframe with the filepath and label from parent directory\nlabels = [str(path.parts[-2]) for path in image_files]\n\n# Map the labels to the label dictionary\nlabels = [lbl_dict[lbl] for lbl in labels]\n\ndf = pd.DataFrame({\"filepath\": [str(path) for path in image_files], \"label\": labels})\n\ndf\n</code></pre> filepath label 0 data/imagenette/train/n03394916/ILSVRC2012_val_00046669.JPEG French horn 1 data/imagenette/train/n03394916/n03394916_58454.JPEG French horn 2 data/imagenette/train/n03394916/n03394916_32588.JPEG French horn 3 data/imagenette/train/n03394916/n03394916_33663.JPEG French horn 4 data/imagenette/train/n03394916/n03394916_27948.JPEG French horn ... ... ... 9464 data/imagenette/train/n02979186/n02979186_8089.JPEG cassette player 9465 data/imagenette/train/n02979186/n02979186_19444.JPEG cassette player 9466 data/imagenette/train/n02979186/n02979186_11074.JPEG cassette player 9467 data/imagenette/train/n02979186/n02979186_2938.JPEG cassette player 9468 data/imagenette/train/n02979186/n02979186_93.JPEG cassette player <p>9469 rows \u00d7 2 columns</p> <p>As an initial step, we will randomly sample 10 samples from each class.</p> <pre><code>initial_samples = (\n    df.groupby(\"label\")\n    .apply(lambda x: x.sample(n=10, random_state=316))\n    .reset_index(drop=True)\n)\n\ninitial_samples\n</code></pre> <pre><code>/var/folders/9y/5mpk58851fq38f8ljx2svvnm0000gn/T/ipykernel_22109/414664958.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda x: x.sample(n=10, random_state=316))\n</code></pre> filepath label 0 data/imagenette/train/n02102040/n02102040_2788.JPEG English springer 1 data/imagenette/train/n02102040/n02102040_3759.JPEG English springer 2 data/imagenette/train/n02102040/n02102040_1916.JPEG English springer 3 data/imagenette/train/n02102040/n02102040_6147.JPEG English springer 4 data/imagenette/train/n02102040/n02102040_403.JPEG English springer ... ... ... 95 data/imagenette/train/n01440764/n01440764_10043.JPEG tench 96 data/imagenette/train/n01440764/n01440764_31535.JPEG tench 97 data/imagenette/train/n01440764/n01440764_12848.JPEG tench 98 data/imagenette/train/n01440764/n01440764_3997.JPEG tench 99 data/imagenette/train/n01440764/n01440764_29788.JPEG tench <p>100 rows \u00d7 2 columns</p> <p>Let's check the distribution of the labels.</p> <pre><code>initial_samples[\"label\"].value_counts()\n</code></pre> <pre><code>label\nEnglish springer    10\nFrench horn         10\ncassette player     10\nchain saw           10\nchurch              10\ngarbage truck       10\ngas pump            10\ngolf ball           10\nparachute           10\ntench               10\nName: count, dtype: int64\n</code></pre> <p>And save it to a parquet file.</p> <pre><code>initial_samples.to_parquet(\"initial_samples.parquet\")\n</code></pre> <pre><code># Get the remaining samples by using pd.Index.difference\nremaining_samples = df[~df.index.isin(initial_samples.index)].reset_index(drop=True)\nremaining_samples\n</code></pre> filepath label 0 data/imagenette/train/n03394916/n03394916_4437.JPEG French horn 1 data/imagenette/train/n03394916/n03394916_42413.JPEG French horn 2 data/imagenette/train/n03394916/n03394916_38808.JPEG French horn 3 data/imagenette/train/n03394916/n03394916_24128.JPEG French horn 4 data/imagenette/train/n03394916/n03394916_11289.JPEG French horn ... ... ... 9364 data/imagenette/train/n02979186/n02979186_8089.JPEG cassette player 9365 data/imagenette/train/n02979186/n02979186_19444.JPEG cassette player 9366 data/imagenette/train/n02979186/n02979186_11074.JPEG cassette player 9367 data/imagenette/train/n02979186/n02979186_2938.JPEG cassette player 9368 data/imagenette/train/n02979186/n02979186_93.JPEG cassette player <p>9369 rows \u00d7 2 columns</p> <pre><code>remaining_samples.to_parquet(\"unlabeled_samples.parquet\")\n</code></pre> <p>Now let's create the evaluation samples which will be used to evaluate the performance of the model. We will use the validation set from the Imagenette dataset as the evaluation set.</p> <pre><code>path = \"data/imagenette/val\"\nimage_files = get_image_files(path)\nlen(image_files)\n</code></pre> <pre><code>3925\n</code></pre> <pre><code>labels = [str(path.parts[-2]) for path in image_files]\n\n# Map the labels to the label dictionary\nlabels = [lbl_dict[lbl] for lbl in labels]\n\nevaluation_samples = pd.DataFrame(\n    {\"filepath\": [str(path) for path in image_files], \"label\": labels}\n)\n\nevaluation_samples\n</code></pre> filepath label 0 data/imagenette/val/n03394916/n03394916_32422.JPEG French horn 1 data/imagenette/val/n03394916/n03394916_69132.JPEG French horn 2 data/imagenette/val/n03394916/n03394916_33771.JPEG French horn 3 data/imagenette/val/n03394916/n03394916_29940.JPEG French horn 4 data/imagenette/val/n03394916/ILSVRC2012_val_00033682.JPEG French horn ... ... ... 3920 data/imagenette/val/n02979186/n02979186_27392.JPEG cassette player 3921 data/imagenette/val/n02979186/n02979186_2742.JPEG cassette player 3922 data/imagenette/val/n02979186/n02979186_2312.JPEG cassette player 3923 data/imagenette/val/n02979186/n02979186_12822.JPEG cassette player 3924 data/imagenette/val/n02979186/ILSVRC2012_val_00042982.JPEG cassette player <p>3925 rows \u00d7 2 columns</p> <pre><code>evaluation_samples.to_parquet(\"evaluation_samples.parquet\")\n</code></pre>"},{"location":"quickstart/#create-an-activelearner","title":"Create an ActiveLearner","text":"<p>Now that we have an initial dataset, we can load it into an <code>ActiveLearner</code> object with a model.</p> <p>Any fastai and timm models are supported. For simplicity, we will use a <code>resnet18</code> model.</p> <pre><code>from active_vision import ActiveLearner\n\nal = ActiveLearner(name=\"cycle-1\")\nal.load_model(model=\"resnet18\", pretrained=True, device=\"mps\")\n</code></pre> <pre><code>2025-02-01 22:44:09.797 | INFO     | active_vision.core:load_model:70 - Loading a pretrained timm model `resnet18` on `mps`\n</code></pre> <p>We can load the initial samples into the <code>ActiveLearner</code> object.</p> <pre><code>initial_samples.head()\n</code></pre> filepath label 0 data/imagenette/train/n02102040/n02102040_2788... English springer 1 data/imagenette/train/n02102040/n02102040_3759... English springer 2 data/imagenette/train/n02102040/n02102040_1916... English springer 3 data/imagenette/train/n02102040/n02102040_6147... English springer 4 data/imagenette/train/n02102040/n02102040_403.... English springer <pre><code>al.load_dataset(\n    initial_samples, filepath_col=\"filepath\", label_col=\"label\", batch_size=8\n)\n</code></pre> <pre><code>2025-02-01 22:44:50.385 | INFO     | active_vision.core:load_dataset:119 - Loading dataset from `filepath` and `label` columns\n2025-02-01 22:44:50.407 | INFO     | active_vision.core:load_dataset:153 - Creating new learner\n2025-02-01 22:44:50.872 | INFO     | active_vision.core:_optimize_learner:97 - Enabled mixed precision training\n2025-02-01 22:44:50.873 | INFO     | active_vision.core:_finalize_setup:105 - Done. Ready to train.\n</code></pre> <p>Let's inspect one batch of the train set.</p> <pre><code>al.show_batch()\n</code></pre> <p></p> <p>You can inspect the train and validation sets too.</p> <pre><code>al.train_set\n</code></pre> filepath label 74 data/imagenette/train/n03445777/n03445777_1058... golf ball 36 data/imagenette/train/n03000684/n03000684_1404... chain saw 68 data/imagenette/train/n03425413/n03425413_2060... gas pump 54 data/imagenette/train/n03417042/n03417042_3669... garbage truck 24 data/imagenette/train/n02979186/n02979186_1658... cassette player ... ... ... 42 data/imagenette/train/n03028079/n03028079_1565... church 30 data/imagenette/train/n03000684/n03000684_9935... chain saw 13 data/imagenette/train/n03394916/n03394916_5292... French horn 59 data/imagenette/train/n03417042/n03417042_79.JPEG garbage truck 0 data/imagenette/train/n02102040/n02102040_2788... English springer <p>80 rows \u00d7 2 columns</p> <pre><code>al.valid_set\n</code></pre> filepath label 96 data/imagenette/train/n01440764/n01440764_3153... tench 73 data/imagenette/train/n03445777/n03445777_4615... golf ball 67 data/imagenette/train/n03425413/n03425413_2016... gas pump 14 data/imagenette/train/n03394916/n03394916_3273... French horn 63 data/imagenette/train/n03425413/n03425413_1357... gas pump 52 data/imagenette/train/n03417042/n03417042_2137... garbage truck 78 data/imagenette/train/n03445777/n03445777_1806... golf ball 10 data/imagenette/train/n03394916/n03394916_6099... French horn 16 data/imagenette/train/n03394916/n03394916_4308... French horn 93 data/imagenette/train/n01440764/n01440764_1383... tench 60 data/imagenette/train/n03425413/n03425413_4937... gas pump 17 data/imagenette/train/n03394916/n03394916_4065... French horn 33 data/imagenette/train/n03000684/n03000684_2624... chain saw 8 data/imagenette/train/n02102040/n02102040_1388... English springer 38 data/imagenette/train/n03000684/n03000684_1371... chain saw 61 data/imagenette/train/n03425413/n03425413_2658... gas pump 39 data/imagenette/train/n03000684/n03000684_2753... chain saw 5 data/imagenette/train/n02102040/n02102040_8296... English springer 62 data/imagenette/train/n03425413/n03425413_1759... gas pump 40 data/imagenette/train/n03028079/n03028079_3132... church"},{"location":"quickstart/#train","title":"Train","text":"<p>Now that we have the initial dataset, we can train the model.</p> <p>But first, let's check the optimal learning rate for the model.</p> <pre><code>al.lr_find()\n</code></pre> <pre><code>2025-02-01 22:45:36.137 | INFO     | active_vision.core:lr_find:194 - Finding optimal learning rate\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> <pre><code>2025-02-01 22:45:41.335 | INFO     | active_vision.core:lr_find:196 - Optimal learning rate: 0.0030199517495930195\n</code></pre> <p></p> <p>Not let's use the optimal learning rate to train the model end-to-end for 3 epochs and 1 epoch of head tuning.</p> <pre><code>al.train(epochs=10, lr=5e-3, head_tuning_epochs=3)\n</code></pre> <pre><code>2025-02-01 22:46:00.935 | INFO     | active_vision.core:train:207 - Training head for 3 epochs\n2025-02-01 22:46:00.936 | INFO     | active_vision.core:train:208 - Training model end-to-end for 10 epochs\n2025-02-01 22:46:00.936 | INFO     | active_vision.core:train:209 - Learning rate: 0.005 with one-cycle learning rate scheduler\n</code></pre> epoch train_loss valid_loss accuracy time 0 3.195328 1.852943 0.350000 00:01 1 2.282106 0.489679 0.850000 00:00 2 1.562541 0.170412 0.950000 00:00 <p></p> epoch train_loss valid_loss accuracy time 0 0.238324 0.192112 0.900000 00:01 1 0.227803 0.171933 0.950000 00:00 2 0.238925 0.134237 0.950000 00:00 3 0.181410 0.155849 0.950000 00:00 4 0.234001 0.228540 0.950000 00:00 5 0.229287 0.266996 0.950000 00:00 6 0.218886 0.201421 0.950000 00:00 7 0.199587 0.219203 0.950000 00:00 8 0.193316 0.216598 0.950000 00:00 9 0.176088 0.222188 0.950000 00:00 <p></p>"},{"location":"quickstart/#evaluate","title":"Evaluate","text":"<p>Now that we have a trained model, we can evaluate it on the evaluation set.</p> <pre><code>evaluation_df = pd.read_parquet(\"evaluation_samples.parquet\")\nevaluation_df\n</code></pre> filepath label 0 data/imagenette/val/n03394916/n03394916_32422.... French horn 1 data/imagenette/val/n03394916/n03394916_69132.... French horn 2 data/imagenette/val/n03394916/n03394916_33771.... French horn 3 data/imagenette/val/n03394916/n03394916_29940.... French horn 4 data/imagenette/val/n03394916/ILSVRC2012_val_0... French horn ... ... ... 3920 data/imagenette/val/n02979186/n02979186_27392.... cassette player 3921 data/imagenette/val/n02979186/n02979186_2742.JPEG cassette player 3922 data/imagenette/val/n02979186/n02979186_2312.JPEG cassette player 3923 data/imagenette/val/n02979186/n02979186_12822.... cassette player 3924 data/imagenette/val/n02979186/ILSVRC2012_val_0... cassette player <p>3925 rows \u00d7 2 columns</p> <pre><code>al.evaluate(evaluation_df, filepath_col=\"filepath\", label_col=\"label\")\n</code></pre> <pre><code>/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> <pre><code>2025-02-01 22:46:36.026 | INFO     | active_vision.core:evaluate:285 - Accuracy: 88.69%\n\n\n\n\n\n0.8868789808917198\n</code></pre> <p>That is a good start. ~88% accuracy is not bad for a first try with only 80 labeled samples. Let's see if we can improve it.</p> <p>Let's save the summary of the cycle.</p> <pre><code>al.summary()\n</code></pre> <pre><code>2025-02-01 22:46:58.694 | INFO     | active_vision.core:summary:578 - Saved results to cycle-1_20250201_224658_acc_88.69%_n_100.parquet\n</code></pre> name accuracy train_set_size valid_set_size dataset_size num_classes model pretrained loss_fn device seed batch_size image_size 0 cycle-1 0.886879 80 20 100 10 resnet18 True FlattenedLoss of CrossEntropyLoss() mps None 8 224 <p>The above will create a .parquet file with the summary of the cycle. This will be useful for tracking the progress of the active learning process.</p>"},{"location":"quickstart/#predict","title":"Predict","text":"<p>Using the model, we can predict the labels of the unlabeled samples and get the most impactful samples to label.</p> <pre><code>df = pd.read_parquet(\"unlabeled_samples.parquet\")\nfilepaths = df[\"filepath\"].tolist()\nlen(filepaths)\n</code></pre> <pre><code>9369\n</code></pre> <pre><code>pred_df = al.predict(filepaths, batch_size=128)\npred_df\n</code></pre> <pre><code>2025-02-01 22:48:06.456 | INFO     | active_vision.core:predict:216 - Running inference on 9369 samples\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> filepath pred_label pred_conf probs logits embeddings 0 data/imagenette/train/n03394916/n03394916_4437... French horn 0.9994 [0.0, 0.9994, 0.0003, 0.0001, 0.0, 0.0, 0.0, 0... [-1.0149, 9.7605, 1.5589, 0.7921, -0.7977, -0.... [-2.2901, 2.3526, 6.4579, 4.2536, 2.6069, -0.7... 1 data/imagenette/train/n03394916/n03394916_4241... French horn 0.9999 [0.0, 0.9999, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0,... [0.1745, 12.1507, -0.4018, -1.8788, 3.0162, -2... [-2.0134, -2.8295, 5.1062, 2.4362, 3.5648, -0.... 2 data/imagenette/train/n03394916/n03394916_3880... French horn 0.5876 [0.0005, 0.5876, 0.0003, 0.1923, 0.0571, 0.006... [-2.0997, 5.0091, -2.5624, 3.8921, 2.677, 0.56... [-1.2764, -1.7355, -0.3358, 3.026, -0.7665, -2... 3 data/imagenette/train/n03394916/n03394916_2412... French horn 0.9960 [0.0, 0.996, 0.0013, 0.0006, 0.0018, 0.0001, 0... [-4.1342, 8.7273, 2.0689, 1.2724, 2.4322, -1.1... [-3.6719, 0.988, 3.3448, -2.0975, 2.0027, 2.49... 4 data/imagenette/train/n03394916/n03394916_1128... French horn 0.9870 [0.0001, 0.987, 0.0, 0.0113, 0.0012, 0.0004, 0... [-0.5818, 9.1891, -2.0218, 4.7223, 2.4576, 1.4... [3.1939, -1.9423, 1.637, 1.6741, 1.6321, -1.24... ... ... ... ... ... ... ... 9364 data/imagenette/train/n02979186/n02979186_8089... cassette player 0.9989 [0.0, 0.0, 0.9989, 0.0001, 0.0, 0.0, 0.0009, 0... [-0.1709, -1.1193, 10.3886, 1.022, -3.1766, -2... [-1.399, 0.6354, -0.2404, 0.1646, -0.2866, 4.4... 9365 data/imagenette/train/n02979186/n02979186_1944... cassette player 0.9975 [0.0, 0.0001, 0.9975, 0.0019, 0.0, 0.0002, 0.0... [-1.2339, -0.2522, 9.287, 3.0204, -2.5014, 0.7... [1.6241, 1.8808, 2.1247, 2.9433, -2.5819, 0.01... 9366 data/imagenette/train/n02979186/n02979186_1107... cassette player 0.9965 [0.0003, 0.0002, 0.9965, 0.0023, 0.0003, 0.0, ... [0.3064, -0.3192, 8.3105, 2.2191, 0.0921, -3.3... [-1.6214, -0.333, -0.5618, 5.5305, -2.7947, 1.... 9367 data/imagenette/train/n02979186/n02979186_2938... cassette player 0.9990 [0.0002, 0.0004, 0.999, 0.0002, 0.0, 0.0, 0.0,... [0.297, 1.1789, 9.0353, 0.3745, -1.4599, -1.22... [-3.9943, 2.4609, -0.4746, 5.7178, -1.1348, -2... 9368 data/imagenette/train/n02979186/n02979186_93.JPEG cassette player 0.9983 [0.0, 0.0, 0.9983, 0.0012, 0.0001, 0.0, 0.0002... [-0.7291, -0.914, 9.3241, 2.5684, -0.2463, -2.... [-0.3718, 2.5391, -0.3689, 5.6201, -0.3824, 0.... <p>9369 rows \u00d7 6 columns</p>"},{"location":"quickstart/#sample","title":"Sample","text":"<p>With the predicted labels, we can sample the most impactful samples to label using active learning strategies.</p> <p>For this example, we will use the <code>sample_combination</code> strategy to sample 50 samples from each strategy listed below in the specified proportions.</p> <pre><code>samples = al.sample_combination(\n    pred_df,\n    num_samples=50,\n    combination={\n        \"least-confidence\": 0.4,\n        \"ratio-of-confidence\": 0.2,\n        \"entropy\": 0.2,\n        \"model-based-outlier\": 0.1,\n        \"random\": 0.1,\n    },\n)\n\nsamples\n</code></pre> <pre><code>2025-02-01 22:48:54.961 | INFO     | active_vision.core:sample_combination:498 - Using combination sampling to get 50 samples\n2025-02-01 22:48:54.965 | INFO     | active_vision.core:sample_uncertain:305 - Using least confidence strategy to get top 20 samples\n2025-02-01 22:48:54.981 | INFO     | active_vision.core:sample_uncertain:328 - Using ratio of confidence strategy to get top 10 samples\n2025-02-01 22:48:55.030 | INFO     | active_vision.core:sample_uncertain:342 - Using entropy strategy to get top 10 samples\n/Users/dnth/Desktop/active-vision/src/active_vision/core.py:345: RuntimeWarning: divide by zero encountered in log2\n  df.loc[:, \"score\"] = df[\"probs\"].apply(lambda x: -np.sum(x * np.log2(x)))\n/Users/dnth/Desktop/active-vision/src/active_vision/core.py:345: RuntimeWarning: invalid value encountered in multiply\n  df.loc[:, \"score\"] = df[\"probs\"].apply(lambda x: -np.sum(x * np.log2(x)))\n2025-02-01 22:48:55.067 | INFO     | active_vision.core:sample_diverse:388 - Using model-based outlier strategy to get top 5 samples\n2025-02-01 22:48:55.067 | INFO     | active_vision.core:predict:216 - Running inference on 20 samples\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> <pre><code>2025-02-01 22:48:55.347 | INFO     | active_vision.core:sample_random:460 - Sampling 5 random samples\n</code></pre> filepath strategy score pred_label pred_conf probs logits embeddings 0 data/imagenette/train/n02979186/n02979186_1337... least-confidence 0.7832 church 0.2168 [0.1246, 0.1754, 0.1861, 0.0186, 0.2168, 0.022... [1.1863, 1.5285, 1.5874, -0.7142, 1.7403, -0.5... [0.2377, -1.946, 0.2599, 2.6317, 0.0457, -0.39... 1 data/imagenette/train/n03417042/n03417042_6809... least-confidence 0.7671 English springer 0.2329 [0.2329, 0.0563, 0.0152, 0.1935, 0.1016, 0.165... [1.6971, 0.2781, -1.0305, 1.5121, 0.8675, 1.35... [-3.1134, -1.0297, -2.949, -0.0299, -2.6318, -... 2 data/imagenette/train/n03417042/n03417042_1228... least-confidence 0.7520 garbage truck 0.2480 [0.0136, 0.0788, 0.1113, 0.2256, 0.134, 0.248,... [-1.3881, 0.3689, 0.7144, 1.4204, 0.8993, 1.51... [-3.2014, -0.3192, 0.4875, 1.5605, -2.9503, 0.... 3 data/imagenette/train/n03445777/ILSVRC2012_val... least-confidence 0.7489 parachute 0.2511 [0.0523, 0.0888, 0.1879, 0.2397, 0.0256, 0.048... [0.2414, 0.771, 1.5211, 1.7646, -0.4716, 0.173... [-2.1577, -0.6424, 0.7163, 4.899, 2.0297, -0.0... 4 data/imagenette/train/n01440764/n01440764_6118... least-confidence 0.7468 parachute 0.2532 [0.2469, 0.1803, 0.015, 0.0427, 0.0, 0.0004, 0... [2.4125, 2.098, -0.3905, 0.6568, -6.4931, -4.0... [2.3019, -0.1646, 0.0037, 4.9036, 0.2177, -0.8... 5 data/imagenette/train/n03417042/n03417042_3796... least-confidence 0.7390 church 0.2610 [0.0097, 0.0347, 0.2573, 0.0808, 0.261, 0.1535... [-1.1992, 0.0708, 2.0745, 0.9159, 2.0887, 1.55... [-2.1991, -2.0034, -0.235, 2.4318, 0.3569, -0.... 6 data/imagenette/train/n03425413/n03425413_1459... least-confidence 0.7385 chain saw 0.2615 [0.2496, 0.0804, 0.0628, 0.2615, 0.0127, 0.047... [1.951, 0.8179, 0.5707, 1.9976, -1.026, 0.2976... [-2.4328, -1.083, -0.361, 3.5946, 0.9601, -2.1... 7 data/imagenette/train/n03445777/n03445777_2207... least-confidence 0.7263 parachute 0.2737 [0.019, 0.1925, 0.1283, 0.0205, 0.0706, 0.0071... [-0.5736, 1.7433, 1.3381, -0.4974, 0.7405, -1.... [0.9713, -3.2046, -0.5145, 2.0419, 0.7177, -0.... 8 data/imagenette/train/n02102040/n02102040_1076... least-confidence 0.7260 chain saw 0.2740 [0.2575, 0.1359, 0.0061, 0.274, 0.0956, 0.001,... [2.2694, 1.6301, -1.4805, 2.3315, 1.2792, -3.2... [2.5813, -0.1416, -2.0389, -2.2112, -1.5039, 3... 9 data/imagenette/train/n03000684/n03000684_1466... least-confidence 0.7233 gas pump 0.2767 [0.0088, 0.1782, 0.0831, 0.1853, 0.0177, 0.040... [-1.5001, 1.5067, 0.7434, 1.546, -0.8016, 0.02... [-1.8619, -0.0667, 1.8241, -3.3802, 1.3863, 2.... 10 data/imagenette/train/n03425413/n03425413_1864... least-confidence 0.7206 garbage truck 0.2794 [0.0078, 0.0121, 0.2249, 0.057, 0.1745, 0.2794... [-1.3753, -0.9285, 1.9904, 0.6176, 1.7364, 2.2... [0.5058, -1.2274, -1.1775, 0.4627, 0.0353, -0.... 11 data/imagenette/train/n03417042/n03417042_1223... least-confidence 0.7168 gas pump 0.2832 [0.025, 0.2146, 0.0005, 0.2588, 0.016, 0.1269,... [-0.9034, 1.2471, -4.8891, 1.4342, -1.3511, 0.... [1.5009, -3.5794, 0.7903, -4.7695, 0.7535, 1.3... 12 data/imagenette/train/n01440764/n01440764_5668... least-confidence 0.7080 parachute 0.2920 [0.0844, 0.2893, 0.0014, 0.073, 0.0001, 0.0007... [1.9209, 3.153, -2.2034, 1.7755, -5.193, -2.89... [1.7147, -3.039, -2.7734, 4.8007, -2.612, -1.4... 13 data/imagenette/train/n03425413/n03425413_88.JPEG least-confidence 0.7071 chain saw 0.2929 [0.0103, 0.0188, 0.0715, 0.2929, 0.0373, 0.276... [-1.1609, -0.5619, 0.7725, 2.1827, 0.1219, 2.1... [-1.8984, -1.801, -0.5466, 0.1875, -0.2696, -2... 14 data/imagenette/train/n03425413/n03425413_6234... least-confidence 0.7045 cassette player 0.2955 [0.0036, 0.0121, 0.2955, 0.2136, 0.0019, 0.001... [-0.5274, 0.6789, 3.8764, 3.5516, -1.1846, -1.... [-1.1586, -1.5979, 0.6346, 4.4901, 0.9681, -2.... 15 data/imagenette/train/n03417042/n03417042_1668... least-confidence 0.7036 chain saw 0.2964 [0.0254, 0.0108, 0.1052, 0.2964, 0.0089, 0.291... [0.6178, -0.2364, 2.0373, 3.0728, -0.438, 3.05... [-1.9726, -4.8946, 0.8208, 2.5173, -3.8419, -2... 16 data/imagenette/train/n03445777/n03445777_4247... least-confidence 0.7012 golf ball 0.2988 [0.0429, 0.0009, 0.258, 0.0017, 0.2062, 0.0048... [1.4205, -2.437, 3.2146, -1.82, 2.9905, -0.761... [-1.1034, -0.4575, -0.8034, 3.1827, -0.7845, -... 17 data/imagenette/train/n03445777/n03445777_646.... least-confidence 0.7008 cassette player 0.2992 [0.0756, 0.0503, 0.2992, 0.2987, 0.006, 0.0125... [1.1265, 0.7181, 2.5015, 2.5, -1.4094, -0.6715... [-2.646, 0.4589, 0.6154, 3.3417, -0.0063, -1.9... 18 data/imagenette/train/n02979186/n02979186_9394... least-confidence 0.6984 church 0.3016 [0.2609, 0.0025, 0.0002, 0.0618, 0.3016, 0.004... [2.7936, -1.8698, -4.2219, 1.3531, 2.9384, -1.... [1.2048, -4.0506, -1.426, 1.0096, 0.5019, -0.3... 19 data/imagenette/train/n03417042/n03417042_1764... least-confidence 0.6982 chain saw 0.3018 [0.0148, 0.0047, 0.1673, 0.3018, 0.0515, 0.200... [-0.9573, -2.1062, 1.4707, 2.0609, 0.2926, 1.6... [-4.4805, -0.7656, 2.3438, -2.386, -1.4532, -1... 20 data/imagenette/train/n03028079/n03028079_236.... ratio-of-confidence 0.9980 church 0.4982 [0.0012, 0.0002, 0.0009, 0.0004, 0.4982, 0.001... [0.1461, -1.7966, -0.1312, -0.9224, 6.1598, -0... [-1.9158, 0.0293, -2.9185, 5.4466, 1.4893, -4.... 21 data/imagenette/train/n01440764/n01440764_8849... ratio-of-confidence 0.9965 French horn 0.3182 [0.0008, 0.3182, 0.0064, 0.1057, 0.0001, 0.001... [-2.4424, 3.6063, -0.2949, 2.5045, -4.2242, -2... [1.7128, 1.7141, 0.4452, 4.5691, -3.717, -0.81... 22 data/imagenette/train/n03425413/n03425413_2131... ratio-of-confidence 0.9951 gas pump 0.4921 [0.0021, 0.0002, 0.0014, 0.0006, 0.4897, 0.002... [-0.2209, -2.4339, -0.5894, -1.4373, 5.2495, 0... [1.8346, -2.7913, 1.1247, 3.9242, 3.2139, -1.9... 23 data/imagenette/train/n03417042/n03417042_1025... ratio-of-confidence 0.9949 garbage truck 0.4712 [0.0, 0.0367, 0.0177, 0.4688, 0.0006, 0.4712, ... [-5.5346, 2.1603, 1.4321, 4.7075, -1.9854, 4.7... [-2.0354, -0.3725, 3.4936, -1.2543, -1.7814, -... 24 data/imagenette/train/n03445777/n03445777_8544... ratio-of-confidence 0.9929 golf ball 0.4791 [0.0019, 0.0, 0.4757, 0.0003, 0.0244, 0.0002, ... [0.2898, -4.0663, 5.7935, -1.5026, 2.8246, -1.... [-1.6029, -0.0789, -1.3203, 2.3646, -1.7308, -... 25 data/imagenette/train/n02979186/n02979186_1028... ratio-of-confidence 0.9928 cassette player 0.4292 [0.0017, 0.0804, 0.4292, 0.4261, 0.008, 0.0001... [-1.9055, 1.9553, 3.6303, 3.6232, -0.347, -5.0... [0.661, -0.879, 0.9711, 6.3615, -1.8835, 0.572... 26 data/imagenette/train/n02979186/n02979186_174.... ratio-of-confidence 0.9928 gas pump 0.4728 [0.0016, 0.001, 0.4694, 0.0023, 0.0103, 0.0006... [-0.8054, -1.2681, 4.8906, -0.434, 1.0697, -1.... [-2.2132, 1.2331, 0.0182, 3.1745, 1.2983, -1.4... 27 data/imagenette/train/n03417042/n03417042_7005... ratio-of-confidence 0.9905 garbage truck 0.4836 [0.0094, 0.0002, 0.479, 0.0178, 0.0004, 0.4836... [0.9137, -2.959, 4.8444, 1.5534, -2.1481, 4.85... [-5.0773, -1.4379, 0.4747, 2.3539, -0.0054, -0... 28 data/imagenette/train/n03028079/n03028079_7073... ratio-of-confidence 0.9902 parachute 0.3277 [0.1374, 0.0006, 0.1855, 0.0042, 0.3245, 0.000... [3.0215, -2.4062, 3.3213, -0.4689, 3.8805, -2.... [-2.5169, -0.1161, -2.0849, 6.913, 0.1524, -3.... 29 data/imagenette/train/n01440764/n01440764_3428... ratio-of-confidence 0.9895 tench 0.4676 [0.0179, 0.0016, 0.0007, 0.0002, 0.0, 0.0001, ... [2.3502, -0.0881, -0.8439, -2.1083, -6.3656, -... [2.0489, -0.5436, -1.8257, 8.6326, -2.1322, -1... 30 data/imagenette/train/n03445777/n03445777_4554... entropy 0.8296 golf ball 0.3049 [0.0693, 0.081, 0.0229, 0.1553, 0.1212, 0.1887... [0.4616, 0.6175, -0.6483, 1.2682, 1.0204, 1.46... [0.8206, -0.299, 0.5261, 4.4358, 1.3322, -2.03... 31 data/imagenette/train/n03425413/n03425413_9229... entropy 0.8130 cassette player 0.3564 [0.1393, 0.0395, 0.3564, 0.1581, 0.0049, 0.012... [1.1223, -0.138, 2.062, 1.2494, -2.2206, -1.30... [0.5329, -0.7068, 1.3603, 0.652, 0.0198, -1.40... 32 data/imagenette/train/n03425413/n03425413_287.... entropy 0.7982 cassette player 0.3625 [0.1304, 0.0647, 0.3625, 0.0102, 0.007, 0.0077... [1.5995, 0.8984, 2.6221, -0.9448, -1.3237, -1.... [-0.0355, 1.2429, 2.0399, 1.95, -0.4611, -2.16... 33 data/imagenette/train/n03417042/n03417042_908.... entropy 0.7812 French horn 0.3538 [0.0043, 0.3538, 0.1463, 0.149, 0.1439, 0.1248... [-2.7491, 1.661, 0.7778, 0.7963, 0.7618, 0.618... [-7.2806, -0.9896, 1.8656, -2.0554, -3.9013, -... 34 data/imagenette/train/n02979186/n02979186_465.... entropy 0.7801 cassette player 0.3180 [0.01, 0.0162, 0.318, 0.178, 0.243, 0.041, 0.0... [-1.1959, -0.7156, 2.2638, 1.6833, 1.9948, 0.2... [-1.0496, -0.4233, -0.2356, 1.7336, 0.0313, -1... 35 data/imagenette/train/n03417042/n03417042_5249... entropy 0.7770 gas pump 0.3602 [0.2176, 0.0115, 0.075, 0.0565, 0.0042, 0.1158... [2.2736, -0.6667, 1.2081, 0.9261, -1.6621, 1.6... [-2.3321, -1.439, 0.5272, -1.0743, 0.0884, 1.3... 36 data/imagenette/train/n02979186/n02979186_603.... entropy 0.7659 parachute 0.3955 [0.0246, 0.0061, 0.105, 0.1808, 0.058, 0.0508,... [-0.1705, -1.567, 1.2804, 1.8236, 0.6872, 0.55... [-1.8714, -1.0384, 0.5632, 5.8721, -1.3883, -2... 37 data/imagenette/train/n03000684/n03000684_1852... entropy 0.7570 cassette player 0.3107 [0.0748, 0.0867, 0.3107, 0.2456, 0.0107, 0.001... [0.1843, 0.3323, 1.609, 1.3735, -1.7552, -3.56... [0.7092, 4.0615, 0.0916, 2.6069, -0.8592, 1.58... 38 data/imagenette/train/n03417042/n03417042_4126... entropy 0.7549 gas pump 0.3585 [0.013, 0.0954, 0.153, 0.0395, 0.1221, 0.1953,... [-0.5105, 1.4799, 1.9525, 0.598, 1.7271, 2.196... [-2.1074, -0.719, 0.3273, -4.9685, -0.2971, 0.... 39 data/imagenette/train/n02979186/n02979186_1288... entropy 0.7484 English springer 0.4436 [0.4436, 0.1239, 0.1386, 0.0856, 0.0053, 0.019... [3.0178, 1.7421, 1.8544, 1.3729, -1.4053, -0.1... [-1.5024, -1.7685, -1.1186, 3.3219, -0.2236, -... 40 data/imagenette/train/n03394916/n03394916_2325... model-based-outlier 0.9000 parachute 0.4584 [0.0077, 0.4082, 0.0652, 0.0305, 0.0034, 0.002... [0.0285, 3.9961, 2.1624, 1.4036, -0.798, -1.07... [-1.8628, 0.4449, 2.5449, 4.2519, 0.3109, -0.2... 41 data/imagenette/train/n03888257/n03888257_3037... model-based-outlier 0.9000 parachute 0.9985 [0.0002, 0.0001, 0.0, 0.0001, 0.0, 0.0001, 0.0... [1.795, 1.3068, -5.9289, 0.588, -0.2612, 0.439... [-0.5929, -1.6006, 0.4943, -1.2933, 2.7818, -0... 42 data/imagenette/train/n02102040/n02102040_3157... model-based-outlier 0.9000 English springer 0.9990 [0.999, 0.0001, 0.0, 0.0001, 0.0, 0.0, 0.0002,... [10.0692, 0.2787, -1.2835, 0.6064, -1.1916, -0... [2.3258, -3.616, -0.5858, 6.3145, 1.105, -0.14... 43 data/imagenette/train/n03394916/n03394916_4728... model-based-outlier 0.9000 parachute 0.4831 [0.0488, 0.2531, 0.0026, 0.0485, 0.0044, 0.025... [1.0755, 2.7207, -1.8696, 1.0683, -1.3336, 0.4... [0.1506, -1.9805, 0.9849, 3.5843, -0.0043, -1.... 44 data/imagenette/train/n03417042/n03417042_1021... model-based-outlier 0.9000 garbage truck 0.9537 [0.0086, 0.0002, 0.0075, 0.0023, 0.0007, 0.953... [2.0034, -1.9979, 1.8706, 0.71, -0.4847, 6.717... [-3.3996, -1.5936, 0.7646, 2.4388, -1.7322, -2... 45 data/imagenette/train/n03417042/n03417042_1858... random 0.0000 garbage truck 0.7858 [0.0143, 0.0061, 0.0087, 0.1633, 0.0015, 0.785... [0.3009, -0.5477, -0.1979, 2.7391, -1.9379, 4.... [-3.5253, -2.8105, 3.3649, -1.5904, -2.0809, -... 46 data/imagenette/train/n03394916/n03394916_2376... random 0.0000 French horn 1.0000 [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ... [-3.3366, 12.358, 0.1247, 0.7122, 1.0722, -2.4... [-0.7454, -2.0169, 5.2131, 1.7518, 1.3361, 0.4... 47 data/imagenette/train/n01440764/n01440764_1166... random 0.0000 tench 0.9899 [0.0038, 0.0015, 0.0001, 0.0002, 0.0, 0.0, 0.0... [2.0583, 1.1105, -1.2277, -0.7113, -5.8862, -2... [4.0684, -1.9906, -0.8653, 5.5249, -1.2073, -0... 48 data/imagenette/train/n02979186/n02979186_1834... random 0.0000 cassette player 0.9763 [0.0001, 0.0, 0.9763, 0.0001, 0.0009, 0.0, 0.0... [-0.2952, -2.528, 8.5269, -0.8405, 1.5539, -1.... [-1.0581, 0.6868, 0.1566, 2.4419, 1.0955, 0.19... 49 data/imagenette/train/n03888257/n03888257_1158... random 0.0000 parachute 1.0000 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ... [0.2342, -3.6737, -3.615, -4.0797, -0.533, 1.2... [-1.6263, 2.0753, -2.3862, -0.6846, -1.6283, -..."},{"location":"quickstart/#label","title":"Label","text":"<p>Let's label the samples and save them to a parquet file named <code>combination.parquet</code>.</p> <pre><code>al.label(samples, output_filename=\"combination.parquet\")\n</code></pre> <pre><code>2025-02-01 22:50:11.038 | INFO     | active_vision.core:label:612 - Launching labeling interface for 50 samples\n\n\n* Running on local URL:  http://127.0.0.1:7860\n\nTo create a public link, set `share=True` in `launch()`.\n</code></pre> <p></p> <p>The Gradio interface will open up and you can label the samples. You could also see the confidence of the model for each sample to debug the model.</p> <p>We can inspect the samples we just labeled.</p> <pre><code>labeled_df = pd.read_parquet(\"combination.parquet\")\n\nlabeled_df\n</code></pre> filepath label 0 data/imagenette/train/n02979186/n02979186_1337... cassette player 1 data/imagenette/train/n03417042/n03417042_6809... garbage truck 2 data/imagenette/train/n03417042/n03417042_1228... garbage truck 3 data/imagenette/train/n03445777/ILSVRC2012_val... golf ball 4 data/imagenette/train/n01440764/n01440764_6118... tench 5 data/imagenette/train/n03417042/n03417042_3796... garbage truck 6 data/imagenette/train/n03425413/n03425413_1459... gas pump 7 data/imagenette/train/n03445777/n03445777_2207... golf ball 8 data/imagenette/train/n02102040/n02102040_1076... English springer 9 data/imagenette/train/n03000684/n03000684_1466... chain saw 10 data/imagenette/train/n03425413/n03425413_1864... gas pump 11 data/imagenette/train/n03417042/n03417042_1223... garbage truck 12 data/imagenette/train/n01440764/n01440764_5668... tench 13 data/imagenette/train/n03425413/n03425413_88.JPEG gas pump 14 data/imagenette/train/n03425413/n03425413_6234... gas pump 15 data/imagenette/train/n03417042/n03417042_1668... garbage truck 16 data/imagenette/train/n03445777/n03445777_4247... golf ball 17 data/imagenette/train/n03445777/n03445777_646.... golf ball 18 data/imagenette/train/n02979186/n02979186_9394... cassette player 19 data/imagenette/train/n03417042/n03417042_1764... garbage truck 20 data/imagenette/train/n03028079/n03028079_236.... church 21 data/imagenette/train/n01440764/n01440764_8849... tench 22 data/imagenette/train/n03425413/n03425413_2131... gas pump 23 data/imagenette/train/n03417042/n03417042_1025... garbage truck 24 data/imagenette/train/n03445777/n03445777_8544... golf ball 25 data/imagenette/train/n02979186/n02979186_1028... cassette player 26 data/imagenette/train/n02979186/n02979186_174.... cassette player 27 data/imagenette/train/n03417042/n03417042_7005... garbage truck 28 data/imagenette/train/n03028079/n03028079_7073... church 29 data/imagenette/train/n01440764/n01440764_3428... tench 30 data/imagenette/train/n03445777/n03445777_4554... golf ball 31 data/imagenette/train/n03425413/n03425413_9229... gas pump 32 data/imagenette/train/n03425413/n03425413_287.... gas pump 33 data/imagenette/train/n03417042/n03417042_908.... garbage truck 34 data/imagenette/train/n02979186/n02979186_465.... gas pump 35 data/imagenette/train/n03417042/n03417042_5249... garbage truck 36 data/imagenette/train/n03000684/n03000684_1852... chain saw 37 data/imagenette/train/n03417042/n03417042_4126... garbage truck 38 data/imagenette/train/n02979186/n02979186_1288... cassette player 39 data/imagenette/train/n03394916/n03394916_2325... French horn 40 data/imagenette/train/n03888257/n03888257_3037... parachute 41 data/imagenette/train/n02102040/n02102040_3157... English springer 42 data/imagenette/train/n03394916/n03394916_4728... French horn 43 data/imagenette/train/n03417042/n03417042_1021... garbage truck 44 data/imagenette/train/n03417042/n03417042_1858... garbage truck 45 data/imagenette/train/n03394916/n03394916_2376... French horn 46 data/imagenette/train/n01440764/n01440764_1166... tench 47 data/imagenette/train/n02979186/n02979186_1834... cassette player 48 data/imagenette/train/n03888257/n03888257_1158... parachute"},{"location":"quickstart/#add-to-train-set","title":"Add to train set","text":"<p>Now that we have labeled the samples, we can add them to the train set and save it to a parquet file named <code>active_labeled.parquet</code>.</p> <pre><code>al.add_to_dataset(labeled_df, output_filename=\"active_labeled.parquet\")\n</code></pre> <pre><code>2025-02-01 22:55:13.929 | INFO     | active_vision.core:add_to_dataset:1060 - Adding 49 samples to dataset\n2025-02-01 22:55:13.932 | INFO     | active_vision.core:add_to_dataset:1068 - Saved dataset to active_labeled.parquet\n</code></pre>"},{"location":"quickstart/#repeat","title":"Repeat","text":"<p>Congratulations! You have completed the first cycle of active learning. We now have a small dataset and a trained model. Now whats left is to repeat the process of predicting, sampling, labeling, and adding to the train set until we have a good model.</p>"},{"location":"train/","title":"Training the Final Model","text":""},{"location":"train/#introduction","title":"Introduction","text":"<p>Now that we have a dataset of labeled samples from the active learning process, we can train a model on this dataset.</p> <pre><code>import pandas as pd\n\ndf = pd.read_parquet(\"active_labeled.parquet\")\ndf\n</code></pre> filepath label 0 data/imagenette/train/n02102040/n02102040_2788... English springer 1 data/imagenette/train/n02102040/n02102040_3759... English springer 2 data/imagenette/train/n02102040/n02102040_1916... English springer 3 data/imagenette/train/n02102040/n02102040_6147... English springer 4 data/imagenette/train/n02102040/n02102040_403.... English springer ... ... ... 238 data/imagenette/train/n03417042/n03417042_1869... garbage truck 239 data/imagenette/train/n02102040/n02102040_6763... English springer 240 data/imagenette/train/n01440764/n01440764_1455... tench 241 data/imagenette/train/n03028079/n03028079_2489... church 242 data/imagenette/train/n03425413/n03425413_2110... gas pump <p>243 rows \u00d7 2 columns</p>"},{"location":"train/#loading-the-data","title":"Loading the data","text":"<p>We will use the fastai to train a model on this dataset. Feel free to use any other library you prefer.</p> <pre><code>from fastai.vision.all import *\n\nbase_path = \".\"\ndls = ImageDataLoaders.from_df(\n    df,\n    path=base_path,\n    valid_pct=0.2,\n    fn_col=\"filepath\",\n    label_col=\"label\",\n    bs=16,\n    item_tfms=Resize(224),\n    # batch_tfms=aug_transforms(size=224),\n)\n\ndls.show_batch()\n</code></pre> <p></p> <pre><code>learn = vision_learner(dls, \"vit_small_patch16_224\", metrics=accuracy).to_fp16()\n# learn.lr_find(suggest_funcs=(valley, slide))\n</code></pre> <pre><code>learn.fine_tune(10, base_lr=5e-3, freeze_epochs=3, cbs=ShowGraphCallback())\n</code></pre> <pre><code>/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> epoch train_loss valid_loss accuracy time 0 3.229721 1.472226 0.541667 00:08 1 1.934528 0.310813 0.916667 00:02 2 1.189405 0.198128 0.958333 00:02 <p></p> epoch train_loss valid_loss accuracy time 0 0.050988 0.175159 0.958333 00:05 1 0.060211 0.165249 0.958333 00:03 2 0.039981 0.193097 0.937500 00:03 3 0.028811 0.185286 0.916667 00:03 4 0.021800 0.170266 0.916667 00:03 5 0.016554 0.166251 0.937500 00:03 6 0.017647 0.179208 0.916667 00:03 7 0.016122 0.185861 0.916667 00:03 8 0.013686 0.192955 0.916667 00:03 9 0.011061 0.198078 0.916667 00:03 <p></p>"},{"location":"train/#evaluating-the-model","title":"Evaluating the model","text":"<pre><code>test_df = pd.read_parquet(\"evaluation_samples.parquet\")\ntest_df\n</code></pre> filepath label 0 data/imagenette/val/n03394916/n03394916_32422.JPEG French horn 1 data/imagenette/val/n03394916/n03394916_69132.JPEG French horn 2 data/imagenette/val/n03394916/n03394916_33771.JPEG French horn 3 data/imagenette/val/n03394916/n03394916_29940.JPEG French horn 4 data/imagenette/val/n03394916/ILSVRC2012_val_00033682.JPEG French horn ... ... ... 3920 data/imagenette/val/n02979186/n02979186_27392.JPEG cassette player 3921 data/imagenette/val/n02979186/n02979186_2742.JPEG cassette player 3922 data/imagenette/val/n02979186/n02979186_2312.JPEG cassette player 3923 data/imagenette/val/n02979186/n02979186_12822.JPEG cassette player 3924 data/imagenette/val/n02979186/ILSVRC2012_val_00042982.JPEG cassette player <p>3925 rows \u00d7 2 columns</p> <pre><code>filepaths = test_df[\"filepath\"].tolist()\nlabels = test_df[\"label\"].tolist()\ntest_dl = dls.test_dl(filepaths, bs=16)\npreds, _, cls_preds = learn.get_preds(dl=test_dl, with_decoded=True)\n\nresults = pd.DataFrame(\n    {\n        \"filepath\": filepaths,\n        \"label\": labels,\n        \"pred_label\": [learn.dls.vocab[i] for i in cls_preds.numpy()],\n    }\n)\n\naccuracy = float((results[\"label\"] == results[\"pred_label\"]).mean())\naccuracy\n</code></pre> <pre><code>/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n/Users/dnth/Desktop/active-vision/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\n</code></pre> <pre><code>0.9936305732484076\n</code></pre> <p>With a mere 243 labeled samples, we have achieved an accuracy of 99.36% on the test set. The entire dataset contains over 9000 images, but it turns out that using active learning, we can achieve a high accuracy with a small number of labeled samples.</p>"}]}